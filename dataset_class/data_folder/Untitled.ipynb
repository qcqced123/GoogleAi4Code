{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b94680d-57cb-4c51-b9e7-3c79529d3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d084c631-2821-463b-8a66-92ca69bee267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_filtering(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Add eps value for zero embedding, because competition metric is cosine similarity\n",
    "    Cosine Similarity will be returned NaN, when input value has zero\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "    x[x == 0] = eps\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423bedbc-c23e-48e7-8742-0927e9f9b0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  4,  5,  6,  3,  5,  4, -1, -1, -1],\n",
       "        [ 1,  2,  4,  5,  6,  3,  5,  4, -1, -1, -1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([\n",
    "    [1,2,4,5,6,3,5,4,-1,-1,-1],\n",
    "    [1,2,4,5,6,3,5,4,-1,-1,-1]\n",
    "    ])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dde9f0-8c1c-4967-9b7c-2dd2e78a512e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 5, 6, 3, 5, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0][test[0] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f8db1f-3520-4ed9-aec0-33e667e85ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  4,  5,  6,  3,  5,  4, -1, -1, -1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([1,2,4,5,6,3,5,4,-1,-1,-1])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe07773-0350-47b6-bc0a-3fd827b6c308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 5, 6, 3, 5, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff9888f-fa89-430f-8e69-1570fda38c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.3444,  0.5577, -0.7954,  ..., -0.2724,  0.3714,  0.4175],\n",
       "         [-0.8089, -0.3178,  1.5001,  ..., -0.8454,  0.0325,  0.9044],\n",
       "         [-0.6807,  0.5505, -0.4885,  ...,  0.5007,  0.1895,  0.2763],\n",
       "         ...,\n",
       "         [-1.2769, -0.3433, -0.9795,  ...,  0.5901,  0.6422, -0.0337],\n",
       "         [ 2.2834, -0.0694, -1.0468,  ...,  0.3699, -0.9568, -0.8544],\n",
       "         [ 0.6269, -0.4410, -0.0246,  ...,  0.4569,  0.0257, -1.7585]]),\n",
       " torch.Size([40, 1024]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.randn(40, 1024)\n",
    "test, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a74654-9370-4b69-a7a3-75eff60d5706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.8089, -0.3178,  1.5001,  ..., -0.8454,  0.0325,  0.9044],\n",
       "        [-0.6807,  0.5505, -0.4885,  ...,  0.5007,  0.1895,  0.2763],\n",
       "        ...,\n",
       "        [-1.2769, -0.3433, -0.9795,  ...,  0.5901,  0.6422, -0.0337],\n",
       "        [ 2.2834, -0.0694, -1.0468,  ...,  0.3699, -0.9568, -0.8544],\n",
       "        [ 0.6269, -0.4410, -0.0246,  ...,  0.4569,  0.0257, -1.7585]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0] = 0\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e2fee42-dbe3-4b5d-82d6-8953ac97c3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000e-08, 1.0000e-08, 1.0000e-08,  ..., 1.0000e-08, 1.0000e-08,\n",
       "          1.0000e-08],\n",
       "         [4.2806e-01, 1.0195e-02, 5.0638e+00,  ..., 5.1090e-01, 1.1206e-06,\n",
       "          6.6914e-01],\n",
       "         [2.1464e-01, 9.1817e-02, 5.6960e-02,  ..., 6.2874e-02, 1.2907e-03,\n",
       "          5.8280e-03],\n",
       "         ...,\n",
       "         [2.6588e+00, 1.3890e-02, 9.2048e-01,  ..., 1.2129e-01, 1.7013e-01,\n",
       "          1.2829e-06],\n",
       "         [2.7183e+01, 2.3170e-05, 1.2006e+00,  ..., 1.8714e-02, 8.3804e-01,\n",
       "          5.3299e-01],\n",
       "         [1.5445e-01, 3.7813e-02, 3.6707e-07,  ..., 4.3568e-02, 4.3293e-07,\n",
       "          9.5616e+00]]),\n",
       " torch.Size([40, 1024]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = zero_filtering(torch.pow(test, 4))\n",
    "embedding, embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d4c508-2bd7-4f55-8362-7c6d806bbc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000e-08, 2.6001e+00, 3.6870e+00, 2.9245e+00, 2.7390e+00, 3.3937e+00,\n",
       "         2.8184e+00, 2.6545e+00, 2.7991e+00, 2.7647e+00, 3.3300e+00, 2.4390e+00,\n",
       "         2.6048e+00, 2.5761e+00, 3.0490e+00, 2.8663e+00, 3.1534e+00, 2.9484e+00,\n",
       "         3.1056e+00, 3.3230e+00, 2.9196e+00, 2.9802e+00, 2.8987e+00, 2.9183e+00,\n",
       "         4.0912e+00, 3.4832e+00, 2.9202e+00, 3.2325e+00, 2.8156e+00, 2.9903e+00,\n",
       "         2.6084e+00, 2.7154e+00, 2.4076e+00, 3.3756e+00, 3.0120e+00, 3.0570e+00,\n",
       "         3.5320e+00, 3.2649e+00, 3.2761e+00, 3.4769e+00]),\n",
       " torch.Size([40]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_embedding = torch.mean(embedding, 1)\n",
    "pool_embedding, pool_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c71b88da-51c3-46f2-85e6-16d21bbcd1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 1.2698, 1.3857, 1.3077, 1.2865, 1.3573, 1.2957, 1.2764, 1.2935,\n",
       "        1.2895, 1.3509, 1.2497, 1.2704, 1.2669, 1.3214, 1.3012, 1.3326, 1.3104,\n",
       "        1.3275, 1.3501, 1.3072, 1.3139, 1.3048, 1.3070, 1.4222, 1.3661, 1.3072,\n",
       "        1.3409, 1.2954, 1.3150, 1.2708, 1.2837, 1.2456, 1.3555, 1.3174, 1.3223,\n",
       "        1.3709, 1.3442, 1.3454, 1.3655])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gem_embedding = torch.pow(pool_embedding, 1/4)\n",
    "gem_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db77484-362e-4686-9bf6-137a247e1bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
