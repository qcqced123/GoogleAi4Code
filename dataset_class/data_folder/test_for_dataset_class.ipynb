{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b9a78ab-e4ae-441e-ab82-bd42d9725a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d823cb54-4307-4e28-b0d7-b846233e9971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/Users/qcqced/Desktop/SAMSUNG/venv/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    model = 'microsoft/deberta-v3-large'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ecd8762-4087-417c-b66d-766f867cb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dataset Utils Function \"\"\"\n",
    "\n",
    "def markdown_to_text(markdown_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a markdown string to plaintext by beautifulsoup\n",
    "    md -> html -> string\n",
    "    Args:\n",
    "        markdown_string: str, markdown string\n",
    "    Example:\n",
    "        markdown_to_text(md.loc['63a93277', 'source'])\n",
    "        => md == pd.DataFrame filtered by cell_type == 'markdown'\n",
    "    Reference:\n",
    "        https://gist.github.com/lorey/eb15a7f3338f959a78cc3661fbc255fe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        html = markdown.markdown(markdown_string)\n",
    "        html = re.sub(r'<pre>(.*?)</pre>', ' ', html)  # remove code snippets\n",
    "        html = re.sub(r'<code>(.*?)</code >', ' ', html)  # remove code snippets\n",
    "        soup = BeautifulSoup(html, \"html.parser\")  # extract text\n",
    "        text = ''.join(soup.findAll(text=True)).strip()  # extract text\n",
    "        if len(text) == 0:\n",
    "            text = markdown_string\n",
    "            if text[0] == \"!\" and text[1] == \"[\":\n",
    "                for m in range(2, len(text)):\n",
    "                    if text[m] == \"]\":\n",
    "                        text = 'embedded ' + text[2:m] + ' image'\n",
    "                        break\n",
    "            elif '<img src' in markdown_string or '.png' in markdown_string or 'gif' in markdown_string or '.jpg' in markdown_string:\n",
    "                text = 'embedded image'\n",
    "    except:\n",
    "        text = markdown_string\n",
    "    return text\n",
    "\n",
    "def code_tokenizer(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokenize code text by python built-in tokenizer for code scanning\n",
    "    Args:\n",
    "        code: str, code text\n",
    "    Example:\n",
    "        code = code.loc['3a6623e3','source']\n",
    "        code_text = tokenize.generate_tokens(io.StringIO(code).readline)\n",
    "        ' '.join([tok.string for tok in code_text if tok.type==1 or tok.type==2 or tok.type==3 or tok.type==60])\n",
    "    Reference:\n",
    "        https://docs.python.org/3/library/tokenize.html\n",
    "        https://www.kaggle.com/code/haithamaliryan/ai4code-extract-all-functions-variables-names/notebook\n",
    "    \"\"\"\n",
    "    try:\n",
    "        code_text = tokenize.generate_tokens(io.StringIO(code).readline)\n",
    "        code_str = ' '.join([tok.string for tok in code_text if tok.type == 1 or tok.type == 2 or tok.type == 3 or tok.type == 60])\n",
    "        if len(code_str) == 0:\n",
    "            code_str = \"unknown\"\n",
    "    except:\n",
    "        code_str = code\n",
    "    return code_str\n",
    "\n",
    "def tokenizing(cfg: CFG, text: str) -> any:\n",
    "    \"\"\"\n",
    "    Preprocess text for CLIP\n",
    "    Args:\n",
    "        cfg: configuration.CFG, needed to load tokenizer from Huggingface AutoTokenizer\n",
    "        text: text from dataframe or any other dataset, please pass str type\n",
    "    \"\"\"\n",
    "    inputs = cfg.tokenizer(\n",
    "        text,\n",
    "        max_length=cfg.max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors=None,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.as_tensor(v)\n",
    "    return inputs\n",
    "\n",
    "def sequence_length(cfg: CFG, text_list: list) -> list:\n",
    "    \"\"\" Get sequence length of all text data for checking statistics value \"\"\"\n",
    "    length_list = []\n",
    "    for text in text_list:\n",
    "        tmp_text = tokenizing(cfg, text)['attention_mask']\n",
    "        length_list.append(tmp_text.count(1))\n",
    "    return length_list\n",
    "\n",
    "def group_kfold(df: pd.DataFrame, cfg: CFG) -> pd.DataFrame:\n",
    "    \"\"\" GroupKFold \"\"\"\n",
    "    fold = GroupKFold(\n",
    "        n_splits=cfg.n_folds,\n",
    "    )\n",
    "    df['fold'] = -1\n",
    "    for num, (tx, vx) in enumerate(fold.split(X=df, y=df['pct_rank'], groups=df['ancestor_id'])):\n",
    "        df.loc[vx, \"fold\"] = int(num)\n",
    "    return df\n",
    "\n",
    "def check_null(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\" check if input dataframe has null type object...etc \"\"\"\n",
    "    return df.isnull().sum()\n",
    "\n",
    "def drop_columns(df: pd.DataFrame, drop_list: list[int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    drop columns by drop_list\n",
    "    Args:\n",
    "        drop_list: list type, element is column index in dataframe which do you want to drop\n",
    "    example:\n",
    "        drop_list = [0, 1, 2]\n",
    "    \"\"\"\n",
    "    tmp_index = [i for i in range(len(df.columns))]\n",
    "    for idx in drop_list.sort():\n",
    "        tmp_index.remove(idx)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8176ea1-a442-461b-ac0e-81180fbece1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8a2564b730a575</td>\n",
       "      <td>8395ab7c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np\\nimport matplotlib.pyplot a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8a2564b730a575</td>\n",
       "      <td>ebc844d6</td>\n",
       "      <td>code</td>\n",
       "      <td>df_train = pd.read_csv('../input/tensorflow-gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8a2564b730a575</td>\n",
       "      <td>49251f17</td>\n",
       "      <td>code</td>\n",
       "      <td>def bbox_inv_iou(boxA, boxB):\\n    \"\"\"Copied f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8a2564b730a575</td>\n",
       "      <td>3a6623e3</td>\n",
       "      <td>code</td>\n",
       "      <td>test_sequence_id = np.unique(df_train.sequence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8a2564b730a575</td>\n",
       "      <td>24e09d1a</td>\n",
       "      <td>code</td>\n",
       "      <td>seq_df_with_cots_ids, stats = find_unique_cots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370641</th>\n",
       "      <td>a3faba2871daaa</td>\n",
       "      <td>5ce07f7e</td>\n",
       "      <td>markdown</td>\n",
       "      <td>Lets check a random image and its label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370642</th>\n",
       "      <td>a3faba2871daaa</td>\n",
       "      <td>ad67d1e9</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We can see that there are 5 directories of 5 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370643</th>\n",
       "      <td>a3faba2871daaa</td>\n",
       "      <td>c24be090</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Also print Misclassified Images:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370644</th>\n",
       "      <td>a3faba2871daaa</td>\n",
       "      <td>df63943f</td>\n",
       "      <td>markdown</td>\n",
       "      <td>**Normalization**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370645</th>\n",
       "      <td>a3faba2871daaa</td>\n",
       "      <td>ee0d89df</td>\n",
       "      <td>markdown</td>\n",
       "      <td>## Visualizing Predictons on the Validation Set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6370646 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id   cell_id cell_type  \\\n",
       "0        8a2564b730a575  8395ab7c      code   \n",
       "1        8a2564b730a575  ebc844d6      code   \n",
       "2        8a2564b730a575  49251f17      code   \n",
       "3        8a2564b730a575  3a6623e3      code   \n",
       "4        8a2564b730a575  24e09d1a      code   \n",
       "...                 ...       ...       ...   \n",
       "6370641  a3faba2871daaa  5ce07f7e  markdown   \n",
       "6370642  a3faba2871daaa  ad67d1e9  markdown   \n",
       "6370643  a3faba2871daaa  c24be090  markdown   \n",
       "6370644  a3faba2871daaa  df63943f  markdown   \n",
       "6370645  a3faba2871daaa  ee0d89df  markdown   \n",
       "\n",
       "                                                    source  \n",
       "0        import numpy as np\\nimport matplotlib.pyplot a...  \n",
       "1        df_train = pd.read_csv('../input/tensorflow-gr...  \n",
       "2        def bbox_inv_iou(boxA, boxB):\\n    \"\"\"Copied f...  \n",
       "3        test_sequence_id = np.unique(df_train.sequence...  \n",
       "4        seq_df_with_cots_ids, stats = find_unique_cots...  \n",
       "...                                                    ...  \n",
       "6370641            Lets check a random image and its label  \n",
       "6370642  We can see that there are 5 directories of 5 d...  \n",
       "6370643                ## Also print Misclassified Images:  \n",
       "6370644                                  **Normalization**  \n",
       "6370645    ## Visualizing Predictons on the Validation Set  \n",
       "\n",
       "[6370646 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ancestor_id, parent_id 모두 지워도 될 것 같다. 어차피 test dataset에는 등장 안해서 context로 사용할 수 없음\n",
    "\"\"\"\n",
    "df = pd.read_csv(\n",
    "    'train.csv',\n",
    "    keep_default_na=False\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "47c4d1a4-a61e-41f4-9544-6ab14e919a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [1,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "321b7b9d-8f31-49bc-b945-8ab8ba0e52e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "cell_id      0\n",
       "cell_type    0\n",
       "source       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b33a5db-2ede-4f20-b977-f7e3b43772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenizing(text: str) -> dict:\n",
    "#     inputs = tokenizer.encode_plus(\n",
    "#         text,\n",
    "#         max_length=512,\n",
    "#         padding='max_length',\n",
    "#         truncation=True,\n",
    "#         return_tensors=None,\n",
    "#         add_special_tokens=False,\n",
    "#     )\n",
    "#     return inputs\n",
    "\n",
    "# def sequence_length(text_list: list) -> list:\n",
    "#     length_list = []\n",
    "#     for text in text_list:\n",
    "#         tmp_text = tokenizing(text)['attention_mask']\n",
    "#         length_list.append(tmp_text.count(1))\n",
    "#     return length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87bdad-a5c7-4293-98c9-e579c568f376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1) Apply markdown_to_text, code_tokenizer (o)\n",
    "2) Check sequence length \n",
    "3) Add Rank Feature, ancestor_id (o)\n",
    "    => kaggle notebook에서 만들어서 업로드\n",
    "4) Apply Cross Validation (o)\n",
    "    => drop ancestor, parent feature \n",
    "5) Convert DataFrame shape to dictionary shape\n",
    "    - A: 0, A: 1, A: 2..... \n",
    "    - A: [0, 1, 2, 3, ....]\n",
    "\"\"\"\n",
    "\"\"\" Apply code & markdown tokenizing by custom function \"\"\"\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df.iloc[i, 2] == 'markdown':\n",
    "        df.iloc[i, 3] = markdown_to_text(df.iloc[i, 3])\n",
    "    else:\n",
    "        df.iloc[i, 3] = code_tokenizer(df.iloc[i, 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2bfbc2b-a909-43fe-b005-0f48a2a7bcfc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "# This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here's several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only \"../input/\" directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname _ filenames in os walk '/kaggle/input' for filename in filenames print os path join dirname filename # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"  # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
      "1\n",
      "import numpy as np import pandas as pd import random from sklearn model_selection import train_test_split cross_val_score from sklearn preprocessing import StandardScaler RobustScaler from catboost import CatBoostRegressor from sklearn ensemble import RandomForestRegressor from sklearn metrics import r2_score as r2 from sklearn model_selection import KFold GridSearchCV from datetime import datetime import matplotlib import matplotlib pyplot as plt import seaborn as sns matplotlib inline\n",
      "2\n",
      "import warnings warnings filterwarnings 'ignore'\n",
      "3\n",
      "matplotlib rcParams update 'font.size' 14\n",
      "4\n",
      "def evaluate_preds train_true_values train_pred_values test_true_values test_pred_values print \"Train R2:\\t\" str round r2 train_true_values train_pred_values 3 print \"Test R2:\\t\" str round r2 test_true_values test_pred_values 3 plt figure figsize 18 10 plt subplot 121 sns scatterplot x train_pred_values y train_true_values plt xlabel 'Predicted values' plt ylabel 'True values' plt title 'Train sample prediction' plt subplot 122 sns scatterplot x test_pred_values y test_true_values plt xlabel 'Predicted values' plt ylabel 'True values' plt title 'Test sample prediction' plt show\n",
      "5\n",
      "TRAIN_DATASET_PATH '/kaggle/input/real-estate-price-prediction-moscow/train.csv' TEST_DATASET_PATH '/kaggle/input/real-estate-price-prediction-moscow/test.csv'\n",
      "6\n",
      "train_df pd read_csv TRAIN_DATASET_PATH train_df tail\n",
      "7\n",
      "train_df dtypes\n",
      "8\n",
      "num_feat list train_df select_dtypes exclude 'object' columns obj_feat list train_df select_dtypes include 'object' columns target 'Price' num_feat\n",
      "9\n",
      "test_df pd read_csv TEST_DATASET_PATH test_df tail\n",
      "10\n",
      "print 'Строк в трейне:' train_df shape 0 print 'Строк в тесте' test_df shape 0\n",
      "11\n",
      "train_df shape 1 1 test_df shape 1\n",
      "12\n",
      "submission_df pd read_csv '/kaggle/input/real-estate-price-prediction-moscow/sample_submission.csv'\n",
      "13\n",
      "train_df 'Id' train_df 'Id' astype str\n",
      "14\n",
      "train_df num_feat hist figsize 16 16 plt show\n",
      "15\n",
      "train_df describe T\n",
      "16\n",
      "grid sns jointplot train_df 'Rooms' train_df 'Price' kind 'reg' grid fig set_figwidth 8 grid fig set_figheight 8\n",
      "17\n",
      "grid sns jointplot train_df 'KitchenSquare' train_df 'Price' kind 'reg' grid fig set_figwidth 8 grid fig set_figheight 8\n",
      "18\n",
      "train_df_temp train_df loc train_df 'KitchenSquare' 250 grid sns jointplot train_df_temp 'KitchenSquare' train_df_temp 'Price' kind 'reg' grid fig set_figwidth 8 grid fig set_figheight 8\n",
      "19\n",
      "plt figure figsize 16 8 train_df 'Price' hist bins 30 plt ylabel 'Count' plt xlabel 'Price' plt title 'Target distribution' plt show\n",
      "20\n",
      "correlation train_df corrwith train_df 'Price' sort_values ascending False correlation drop 'Price' inplace True plt figure figsize 16 8 plt bar correlation index correlation plt xticks rotation '90' plt xlabel 'Features' fontsize 15 plt ylabel 'Correlation' fontsize 15 plt title 'Feature correlation' fontsize 15 plt show\n",
      "21\n",
      "class Data def __init__ self \"\"\"Константы для обработки выбросов на основе анализа данных\"\"\" self Square_min 15 self Square_max 300 self LifeSquare_min 10 self LifeSquare_max 280 self Rooms_min 1 self Rooms_max 5 self HouseFloor_min 1 self HouseFloor_max 50 self KitchenSquare_min 3 self KitchenSquare_max 30 self current_year datetime now year self medians None self DistrictId_value_counts None self SquareMeterPrice_by_DistrictId None self Healthcare_1_by_DistrictId None def fit self train_df # медианные значения self medians train_df 'LifeSquare' 'HouseFloor' median # подсчет популярных районов self DistrictId_value_counts dict train_df 'DistrictId' value_counts # подсчет средней цены за м2 по району train_df_temp train_df loc train_df 'Square' self Square_min train_df 'Square' self Square_max train_df_temp \"SquareMeterPrice\" train_df_temp \"Price\" train_df_temp \"Square\" self SquareMeterPrice_by_DistrictId train_df_temp groupby 'DistrictId' as_index False agg 'SquareMeterPrice' 'mean' rename columns 'SquareMeterPrice' 'AverageSquareMeterPrice' # подсчет среднего значения признака Healthcare_1 по району self Healthcare_1_by_DistrictId train_df groupby 'DistrictId' as_index False agg 'Healthcare_1' 'mean' rename columns 'Healthcare_1' 'AverageHealthcare_1' del train_df_temp def transform self train_df # Обработка пропусков train_df 'LifeSquare' 'HouseFloor' train_df 'LifeSquare' 'HouseFloor' fillna self medians # Обработка выбросов # площадь train_df loc train_df 'Square' self Square_max 'Square' self Square_max train_df loc train_df 'Square' self Square_min 'Square' self Square_min # жилая площадь train_df loc train_df 'LifeSquare' self LifeSquare_min 'LifeSquare' self LifeSquare_min train_df loc train_df 'LifeSquare' self LifeSquare_max 'LifeSquare' self LifeSquare_max # площадь кухни train_df loc train_df 'KitchenSquare' self KitchenSquare_min 'KitchenSquare' self KitchenSquare_min train_df loc train_df 'KitchenSquare' self KitchenSquare_max 'KitchenSquare' self KitchenSquare_max # год постройки дома train_df loc train_df 'HouseYear' self current_year 'HouseYear' self current_year # количество комнат train_df loc train_df 'Rooms' self Rooms_max 'Rooms' self Rooms_max train_df loc train_df 'Rooms' self Rooms_min 'Rooms' self Rooms_min # количество этажей train_df loc train_df 'HouseFloor' self HouseFloor_min 'HouseFloor' self HouseFloor_min train_df loc train_df 'HouseFloor' self HouseFloor_max 'HouseFloor' self HouseFloor_max # если этаж больше этажности дома, то присваиваем случайный этаж от self.HouseFloor_min до максимального этажа в доме floor_outliers train_df loc train_df 'Floor' train_df 'HouseFloor' index train_df loc floor_outliers 'Floor' train_df loc floor_outliers 'HouseFloor' apply lambda x self HouseFloor_min if self HouseFloor_min x else np random randint self HouseFloor_min x # Обработка категорий train_df pd concat train_df pd get_dummies train_df 'Ecology_2' prefix 'Ecology_2' dtype 'int8' axis 1 train_df pd concat train_df pd get_dummies train_df 'Ecology_3' prefix 'Ecology_3' dtype 'int8' axis 1 train_df pd concat train_df pd get_dummies train_df 'Shops_2' prefix 'Shops_2' dtype 'int8' axis 1 return train_df def features self train_df # добавление признака популярности района train_df 'DistrictId_counts' train_df 'DistrictId' map self DistrictId_value_counts train_df 'DistrictId_counts' fillna train_df 'DistrictId_counts' median inplace True # добавление признака средней стоимости м2 по району train_df train_df merge self SquareMeterPrice_by_DistrictId on \"DistrictId\" how 'left' train_df 'AverageSquareMeterPrice' fillna train_df 'AverageSquareMeterPrice' median inplace True # добавление признака среднего значения Healthcare_1 по району train_df train_df merge self Healthcare_1_by_DistrictId on \"DistrictId\" how 'left' train_df 'AverageHealthcare_1' fillna train_df 'AverageHealthcare_1' median inplace True return train_df\n",
      "22\n",
      "data_inst Data # тренировочные данные data_inst fit train_df train_df data_inst transform train_df train_df data_inst features train_df # валидационные данные test_df data_inst transform test_df test_df data_inst features test_df\n",
      "23\n",
      "feature_names 'AverageSquareMeterPrice' 'DistrictId_counts' 'Rooms' 'Square' 'LifeSquare' 'KitchenSquare' 'Floor' 'HouseFloor' 'HouseYear' 'Helthcare_2' 'Ecology_1' 'Social_1' 'Social_2' 'Social_3' 'Shops_1' 'Ecology_2_A' 'Ecology_2_B' 'Ecology_3_A' 'Ecology_3_B' 'Shops_2_A' 'Shops_2_B' 'AverageHealthcare_1' target_name 'Price'\n",
      "24\n",
      "train_df train_df feature_names target_name test_df test_df feature_names 'Id' X train_df feature_names y train_df target_name\n",
      "25\n",
      "final_model CatBoostRegressor silent True learning_rate 0.1 iterations 1150 eval_metric 'R2' depth 8 final_model fit X y cv_score cross_val_score final_model X y scoring 'r2' cv KFold n_splits 5 shuffle True random_state 42\n",
      "26\n",
      "print f'R2: {round(cv_score.mean(), 3)}'\n",
      "27\n",
      "feature_importances pd DataFrame zip X columns final_model get_feature_importance columns 'feature_name' 'importance' feature_importances sort_values by 'importance' ascending False inplace True feature_importances head 20\n",
      "28\n",
      "preds_final pd DataFrame preds_final 'Id' test_df 'Id' copy test_df set_index 'Id' inplace True test_df test_df feature_names\n",
      "29\n",
      "y_pred_final final_model predict test_df submission_df 'Price' y_pred_final submission_df to_csv './predictions.csv' index False encoding 'utf-8' sep ',' submission_df head\n",
      "30\n",
      "Деление признаков на числовые и текстовые\n",
      "31\n",
      "Сортировка признаков по важности\n",
      "32\n",
      "Выбросы наблюдаются в: HouseYear, KitchenSquare.\n",
      "Признаки с аномально высоким значением, которые нужно будет ограничить: HouseFloor, LifeSquare, Rooms, Square.\n",
      "33\n",
      "Поиск признаков с выбросами\n",
      "34\n",
      "Выводим сколько строк в тесте и на трейне\n",
      "35\n",
      "Приведение типов\n",
      "36\n",
      "Устанавливаем значения, чтобы везде был одинаковый шрифт и размер\n",
      "37\n",
      "Импортируем необходимые для работы функции и классы\n",
      "38\n",
      "Создаем список признаков, используемых в модели - отбор признаков\n",
      "39\n",
      "Обучение модели на CatBoostRegressor\n",
      "Вычисления гиперпараметров модели при помощи randomized_search() learning_rate=0.1 iterations=1150 depth=8\n",
      "40\n",
      "За выброс посчитаем значения менее 3 кв.м. и больше 30 кв.м.\n",
      "41\n",
      "На обучении на один признак больше, чем на тесте\n",
      "42\n",
      "Считываем обучающий набор данных\n",
      "43\n",
      "Корреляция\n",
      "44\n",
      "Оценка модели\n",
      "45\n",
      "Подключаем предупреждения\n",
      "46\n",
      "График распределения целевой переменной - цены\n",
      "47\n",
      "Загрузка данных\n",
      "48\n",
      "Создание датафрейма с предсказаниями\n",
      "49\n",
      "Указываем путь к файлам с данными\n",
      "50\n",
      "Описание датасета\n",
      "Id - идентификационный номер квартиры\n",
      "DistrictId - идентификационный номер района\n",
      "Rooms - количество комнат\n",
      "Square - площадь\n",
      "LifeSquare - жилая площадь\n",
      "KitchenSquare - площадь кухни\n",
      "Floor - этаж\n",
      "HouseFloor - количество этажей в доме\n",
      "HouseYear - год постройки дома\n",
      "Ecology_1, Ecology_2, Ecology_3 - экологические показатели местности\n",
      "Social_1, Social_2, Social_3 - социальные показатели местности\n",
      "Healthcare_1, Helthcare_2 - показатели местности, связанные с охраной здоровья\n",
      "Shops_1, Shops_2 - показатели, связанные с наличием магазинов, торговых центров\n",
      "Price - цена квартиры\n",
      "51\n",
      "Создания класса подготовки данных\n",
      "52\n",
      "Считываем тестовый набор данных\n",
      "53\n",
      "Значения меньше 1 и больше 250 отсекаем\n",
      "54\n",
      "Задаем функцию для подсчета метрик\n",
      "55\n",
      "Тип данных обучающего сета\n",
      "56\n",
      "Инициализация класса Data\n",
      "57\n",
      "Признаки Rooms, KitchenSquare, HouseFloor имеют в некоторых наблюдениях нулевые значения\n",
      "58\n",
      "import numpy as np # linear algebra import pandas as pd pd set_option \"display.max_rows\" 101 import os print os listdir \"../input\" import cv2 import json import matplotlib pyplot as plt matplotlib inline plt rcParams \"font.size\" 15 import seaborn as sns from collections import Counter import PIL import seaborn as sns from collections import defaultdict from pathlib import Path import cv2 import os import sys import random import pandas as pd import numpy as np import matplotlib pyplot as plt matplotlib inline from skimage transform import resize from skimage morphology import label from skimage feature import hog from skimage import exposure from keras preprocessing image import ImageDataGenerator array_to_img img_to_array load_img from skimage feature import canny from skimage filters import sobel from skimage morphology import watershed from scipy import ndimage as ndi import warnings warnings filterwarnings \"ignore\" from skimage segmentation import mark_boundaries from scipy import signal import cv2 import glob pylab pandas as pd import pydicom numpy as np import tqdm import gc gc enable import glob from skimage transform import resize from skimage morphology import label from skimage feature import hog from skimage import exposure from keras preprocessing image import ImageDataGenerator array_to_img img_to_array load_img from skimage feature import canny from skimage filters import sobel from skimage morphology import watershed from scipy import ndimage as ndi import warnings warnings filterwarnings \"ignore\" from skimage segmentation import mark_boundaries import sys\n",
      "59\n",
      "input_dir \"../input/\"\n",
      "60\n",
      "train_df pd read_csv \"../input/train.csv\" sample_df pd read_csv \"../input/sample_submission.csv\"\n",
      "61\n",
      "class_dict defaultdict int kind_class_dict defaultdict int no_defects_num 0 defects_num 0 for col in range 0 len train_df 4 img_names str i split \"_\" 0 for i in train_df iloc col col 4 0 values if not img_names 0 img_names 1 img_names 2 img_names 3 raise ValueError labels train_df iloc col col 4 1 if labels isna all no_defects_num 1 else defects_num 1 kind_class_dict sum labels isna values False 1 for idx label in enumerate labels isna values tolist if label False class_dict idx 1\n",
      "62\n",
      "print \"the number of images with no defects: {}\" format no_defects_num print \"the number of images with defects: {}\" format defects_num\n",
      "63\n",
      "fig ax plt subplots sns barplot x list class_dict keys y list class_dict values ax ax ax set_title \"the number of images for each class\" ax set_xlabel \"class\" class_dict\n",
      "64\n",
      "fig ax plt subplots sns barplot x list kind_class_dict keys y list kind_class_dict values ax ax ax set_title \"Number of classes included in each image\" ax set_xlabel \"number of classes in the image\" kind_class_dict\n",
      "65\n",
      "train_size_dict defaultdict int train_path Path \"../input/train_images/\" for img_name in train_path iterdir img PIL Image open img_name train_size_dict img size 1\n",
      "66\n",
      "train_size_dict\n",
      "67\n",
      "test_size_dict defaultdict int test_path Path \"../input/test_images/\" for img_name in test_path iterdir img PIL Image open img_name test_size_dict img size 1\n",
      "68\n",
      "test_size_dict\n",
      "69\n",
      "palet 249 192 12 0 185 241 114 0 218 249 50 12\n",
      "70\n",
      "def mask2rgba mask rgba_list for idx in range 4 rgba cv2 cvtColor mask idx cv2 COLOR_GRAY2RGBA rgba 3 rgba 0 100 rgba 3 rgba 3 palet idx rgba_list append rgba return rgba_list\n",
      "71\n",
      "labels train_df iloc 5 5 4 1\n",
      "72\n",
      "def name_and_mask start_idx col start_idx img_names str i split \"_\" 0 for i in train_df iloc col col 4 0 values if not img_names 0 img_names 1 img_names 2 img_names 3 raise ValueError labels train_df iloc col col 4 1 mask np zeros 256 1600 4 dtype np uint8 for idx label in enumerate labels values if label is not np nan mask_label np zeros 1600 256 dtype np uint8 label label split \" \" positions map int label 0 2 length map int label 1 2 for pos le in zip positions length mask_label pos pos le 1 mask idx mask_label reshape 256 1600 order 'F' return img_names 0 mask\n",
      "73\n",
      "def show_mask_image col name mask name_and_mask col img cv2 imread str train_path name #fig, ax = plt.subplots(figsize=(15, 15)) fig ax plt subplots 2 1 figsize 8 8 for ch in range 4 contours _ cv2 findContours mask ch cv2 RETR_LIST cv2 CHAIN_APPROX_NONE for i in range 0 len contours cv2 polylines img contours i True palet ch 2 for i ctr in enumerate contours if i 0 break # Get bounding box x y w h cv2 boundingRect ctr # Getting ROI roi img y y h x x w print roi shape res cv2 resize roi dsize 28 28 interpolation cv2 INTER_CUBIC ax 0 set_title name ax 0 imshow img ax 1 set_title 'One ROI' ax 1 imshow res plt show\n",
      "74\n",
      "fig ax plt subplots 1 4 figsize 15 5 for i in range 4 ax i axis 'off' ax i imshow np ones 50 50 3 dtype np uint8 palet i ax i set_title \"class color: {}\" format i 1 fig suptitle \"each class colors\" plt show\n",
      "75\n",
      "idx_no_defect idx_class_1 idx_class_2 idx_class_3 idx_class_4 idx_class_multi idx_class_triple for col in range 0 len train_df 4 img_names str i split \"_\" 0 for i in train_df iloc col col 4 0 values if not img_names 0 img_names 1 img_names 2 img_names 3 raise ValueError labels train_df iloc col col 4 1 if labels isna all idx_no_defect append col elif labels isna False True True True all idx_class_1 append col elif labels isna True False True True all idx_class_2 append col elif labels isna True True False True all idx_class_3 append col elif labels isna True True True False all idx_class_4 append col elif labels isna sum 1 idx_class_triple append col else idx_class_multi append col\n",
      "76\n",
      "for idx in idx_class_1 1 show_mask_image idx\n",
      "77\n",
      "idx_class_2 1\n",
      "78\n",
      "for idx in idx_class_2 1 show_mask_image idx\n",
      "79\n",
      "for idx in idx_class_3 1 show_mask_image idx\n",
      "80\n",
      "for idx in idx_class_4 1 show_mask_image idx\n",
      "81\n",
      "for idx in idx_class_multi 4 show_mask_image idx\n",
      "82\n",
      "for idx in idx_class_triple 1 show_mask_image idx\n",
      "83\n",
      "#These are the functions provided by kaggle to convert a mask to rle and vice-versa. import numpy as np def mask2rle img width height rle lastColor 0 currentPixel 0 runStart 1 runLength 0 for x in range width for y in range height currentColor img x y if currentColor lastColor if currentColor 127 runStart currentPixel runLength 1 else rle append str runStart rle append str runLength runStart 1 runLength 0 currentPixel 0 elif runStart 1 runLength 1 lastColor currentColor currentPixel 1 return \" \" join rle def rle2mask rle width height mask np zeros width height astype np uint8 array np asarray int x for x in rle split starts array 0 2 lengths array 1 2 current_position 0 for index start in enumerate starts mask int start int start lengths index 1 current_position lengths index return np flipud np rot90 mask reshape height width k 1\n",
      "84\n",
      "ImageId '0002cc93b.jpg_1' train_df head img cv2 imread '../input/train_images/' ImageId split '_' 0 img_masks train_df loc train_df 'ImageId_ClassId' ImageId 'EncodedPixels' tolist p2 p97 np percentile img 2 97 img_rescale exposure rescale_intensity img in_range p2 p97 img_ben cv2 addWeighted img 4 cv2 GaussianBlur img 0 0 10 4 128 # Take the individual ship masks and create a single mask array for all ships all_masks np zeros 256 1600 for mask in img_masks all_masks rle2mask mask 256 1600 fig axarr plt subplots 5 1 figsize 15 15 axarr 0 axis 'off' axarr 1 axis 'off' axarr 2 axis 'off' axarr 3 axis 'off' axarr 0 imshow img axarr 1 imshow all_masks axarr 2 imshow img_rescale #axarr[2].imshow(img_rescale) axarr 3 imshow all_masks alpha 0.7 axarr 4 imshow img_ben plt tight_layout h_pad 0.4 w_pad 0.4 plt show\n",
      "85\n",
      "### Take the images with masks train_masked_df train_df train_df 'EncodedPixels' notnull\n",
      "86\n",
      "view_count 15 #i_chk = np.random.randint(0,len(data), size = view_count) sample_imgs ben_sample_imgs sample_imgs_label file_list '../input/train_images/{}' format train_masked_df 'ImageId_ClassId' values tolist i split '_' 0 for i in range view_count for i in range view_count sample_img cv2 imread file_list i sample_img cv2 cvtColor sample_img cv2 COLOR_BGR2RGB sample_imgs append sample_img sample_imgs_label append file_list i ben_sample_imgs append cv2 addWeighted sample_img 4 cv2 GaussianBlur sample_img 0 0 10 4 128\n",
      "87\n",
      "#plt.imshow(ben_sample_imgs[0]) plt imshow cv2 cvtColor ben_sample_imgs 8 cv2 COLOR_RGB2GRAY\n",
      "88\n",
      "for i in range 5 fig ax plt subplots 1 2 figsize 15 15 ax 0 imshow sample_imgs i ax 1 imshow ben_sample_imgs i #plt.autoscale(tight = 'True' , axis = 'y') ax 0 set_title sample_imgs_label i y 1 ax 1 set_title str sample_imgs_label i ' with preprocess' y 1 ax 0 axis 'off' ax 1 axis 'off'\n",
      "89\n",
      "ben_sample_imgs 0 shape\n",
      "90\n",
      "import cv2 cv2 setNumThreads 0 cv2 ocl setUseOpenCL False import numpy as np import math from scipy ndimage filters import gaussian_filter from functools import wraps import torch import torchvision transforms functional as F def vflip img return cv2 flip img 0 def hflip img return cv2 flip img 1 def random_flip img code return cv2 flip img code def transpose img return img transpose 1 0 2 if len img shape 2 else img transpose 1 0 def rot90 img factor img np rot90 img factor return np ascontiguousarray img def rotate img angle height width img shape 0 2 mat cv2 getRotationMatrix2D width 2 height 2 angle 1.0 img cv2 warpAffine img mat width height flags cv2 INTER_LINEAR borderMode cv2 BORDER_REFLECT_101 return img def shift_scale_rotate img angle scale dx dy height width img shape 2 cc math cos angle 180 math pi scale ss math sin angle 180 math pi scale rotate_matrix np array cc ss ss cc box0 np array 0 0 width 0 width height 0 height box1 box0 np array width 2 height 2 box1 np dot box1 rotate_matrix T np array width 2 dx width height 2 dy height box0 box0 astype np float32 box1 box1 astype np float32 mat cv2 getPerspectiveTransform box0 box1 img cv2 warpPerspective img mat width height flags cv2 INTER_LINEAR borderMode cv2 BORDER_REFLECT_101 return img def center_crop img height width h w c img shape dy h height 2 dx w width 2 y1 dy y2 y1 height x1 dx x2 x1 width img img y1 y2 x1 x2 return img def clip img dtype maxval return np clip img 0 maxval astype dtype def clipped func wraps func def wrapped_function img args kwargs dtype maxval img dtype np max img return clip func img args kwargs dtype maxval return wrapped_function def shift_hsv img hue_shift sat_shift val_shift dtype img dtype img cv2 cvtColor img cv2 COLOR_RGB2HSV astype np int32 h s v cv2 split img h cv2 add h hue_shift h np where h 0 255 h h h np where h 255 h 255 h h h astype dtype s clip cv2 add s sat_shift dtype 255 if dtype np uint8 else 1. v clip cv2 add v val_shift dtype 255 if dtype np uint8 else 1. img cv2 merge h s v astype dtype img cv2 cvtColor img cv2 COLOR_HSV2RGB return img clipped def shift_rgb img r_shift g_shift b_shift img 0 img 0 r_shift img 1 img 1 g_shift img 2 img 2 b_shift return img def clahe img clipLimit 2.0 tileGridSize 8 8 img_yuv cv2 cvtColor img cv2 COLOR_RGB2LAB clahe cv2 createCLAHE clipLimit clipLimit tileGridSize tileGridSize img_yuv 0 clahe apply img_yuv 0 img_output cv2 cvtColor img_yuv cv2 COLOR_LAB2RGB return img_output def blur img ksize return cv2 blur img ksize ksize def median_blur img ksize return cv2 medianBlur img ksize def motion_blur img ksize kernel np zeros ksize ksize xs ys np random randint 0 kernel shape 1 np random randint 0 kernel shape 0 xe ye np random randint 0 kernel shape 1 np random randint 0 kernel shape 0 cv2 line kernel xs ys xe ye 1 thickness 1 return cv2 filter2D img 1 kernel np sum kernel def random_polosa img gray cv2 cvtColor img cv2 COLOR_RGB2GRAY if np mean gray 100 empty np zeros img shape 2 dtype np uint8 xs ys np random randint 0 empty shape 1 np random randint 0 empty shape 0 xe ye np random randint 0 empty shape 1 np random randint 0 empty shape 0 factor np random randint 1 10 3. cv2 line empty xs ys xe ye np max gray factor thickness np random randint 10 100 empty cv2 blur empty 5 5 empty empty gray return cv2 cvtColor empty cv2 COLOR_GRAY2RGB return img def distort1 img k 0 dx 0 dy 0 \"\"\"\"\n",
      "    ## unconverntional augmnet ################################################################################3\n",
      "    ## https://stackoverflow.com/questions/6199636/formulas-for-barrel-pincushion-distortion\n",
      "    ## https://stackoverflow.com/questions/10364201/image-transformation-in-opencv\n",
      "    ## https://stackoverflow.com/questions/2477774/correcting-fisheye-distortion-programmatically\n",
      "    ## http://www.coldvision.io/2017/03/02/advanced-lane-finding-using-opencv/\n",
      "    ## barrel\\pincushion distortion\n",
      "    \"\"\" height width img shape 2 #  map_x, map_y = # cv2.initUndistortRectifyMap(intrinsics, dist_coeffs, None, None, (width,height),cv2.CV_32FC1) # https://stackoverflow.com/questions/6199636/formulas-for-barrel-pincushion-distortion # https://stackoverflow.com/questions/10364201/image-transformation-in-opencv k k 0.00001 dx dx width dy dy height x y np mgrid 0 width 1 0 height 1 x x astype np float32 width 2 dx y y astype np float32 height 2 dy theta np arctan2 y x d x x y y 0.5 r d 1 k d d map_x r np cos theta width 2 dx map_y r np sin theta height 2 dy img cv2 remap img map_x map_y interpolation cv2 INTER_LINEAR borderMode cv2 BORDER_REFLECT_101 return img def distort2 img num_steps 10 xsteps ysteps \"\"\"\n",
      "    #http://pythology.blogspot.sg/2014/03/interpolation-on-regular-distorted-grid.html\n",
      "    ## grid distortion\n",
      "    \"\"\" height width img shape 2 x_step width num_steps xx np zeros width np float32 prev 0 for idx x in enumerate range 0 width x_step start x end x x_step if end width end width cur width else cur prev x_step xsteps idx xx start end np linspace prev cur end start prev cur y_step height num_steps yy np zeros height np float32 prev 0 for idx y in enumerate range 0 height y_step start y end y y_step if end height end height cur height else cur prev y_step ysteps idx yy start end np linspace prev cur end start prev cur map_x map_y np meshgrid xx yy map_x map_x astype np float32 map_y map_y astype np float32 img cv2 remap img map_x map_y interpolation cv2 INTER_LINEAR borderMode cv2 BORDER_REFLECT_101 return img def elastic_transform_fast image alpha sigma alpha_affine random_state None \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
      "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
      "         Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
      "         Proc. of the International Conference on Document Analysis and\n",
      "         Recognition, 2003.\n",
      "     Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
      "    \"\"\" if random_state is None random_state np random RandomState 1234 shape image shape shape_size shape 2 # Random affine center_square np float32 shape_size 2 square_size min shape_size 3 alpha float alpha sigma float sigma alpha_affine float alpha_affine pts1 np float32 center_square square_size center_square 0 square_size center_square 1 square_size center_square square_size pts2 pts1 random_state uniform alpha_affine alpha_affine size pts1 shape astype np float32 M cv2 getAffineTransform pts1 pts2 image cv2 warpAffine image M shape_size 1 borderMode cv2 BORDER_REFLECT_101 dx np float32 gaussian_filter random_state rand shape_size 2 1 sigma alpha dy np float32 gaussian_filter random_state rand shape_size 2 1 sigma alpha x y np meshgrid np arange shape 1 np arange shape 0 mapx np float32 x dx mapy np float32 y dy return cv2 remap image mapx mapy interpolation cv2 INTER_LINEAR borderMode cv2 BORDER_REFLECT_101 def remap_color img bg center max def get_lut img bg center max ma np max img # me = np.mean(img) # th = np.mean([ma, me]) * 1.5 th ma 2 gap 10 channels range2 ma int th for i in range 3 channels i append np linspace bg i gap center i gap int th astype np uint8 channels i append np linspace center i gap max i gap range2 astype np uint8 channels i append max i gap 256 sum map len channels i channels i np hstack channels i return np dstack channels # img = adjust_gamma(img, 5.) gray cv2 cvtColor img cv2 COLOR_RGB2GRAY if np mean gray 100 return img lut get_lut img bg center max res cv2 LUT img lut astype np uint8 return res def invert img return 255 img def channel_shuffle img ch_arr 0 1 2 np random shuffle ch_arr img img ch_arr return img clipped def gauss_noise image var row col ch image shape mean var # var = 30 sigma var 0.5 gauss np random normal mean sigma row col ch gauss gauss reshape row col ch gauss gauss np min gauss astype np uint8 return image astype np int32 gauss def salt_pepper_noise image #todo s_vs_p 0.5 amount 0.004 noisy image # Salt mode num_salt np ceil amount image size s_vs_p coords np random randint 0 i 1 int num_salt for i in image shape noisy coords 255 # Pepper mode num_pepper np ceil amount image size 1. s_vs_p coords np random randint 0 i 1 int num_pepper for i in image shape noisy coords 0 return noisy def poisson_noise image #todo vals len np unique image vals 2 np ceil np log2 vals noisy np random poisson image vals float vals return noisy def speckle_noise image #todo row col ch image shape gauss np random randn row col ch gauss gauss reshape row col ch noisy image image gauss return noisy clipped def random_brightness img alpha return alpha img clipped def random_contrast img alpha gray cv2 cvtColor img cv2 COLOR_RGB2GRAY gray 3.0 1.0 alpha gray size np sum gray return alpha img gray def to_three_channel_gray img gray cv2 cvtColor img cv2 COLOR_RGB2GRAY invgray 255 gray clahe cv2 createCLAHE clipLimit 2 tileGridSize 8 8 if np mean invgray np mean gray invgray gray gray invgray res invgray gray clahe apply invgray return cv2 merge res def to_gray img gray cv2 cvtColor img cv2 COLOR_RGB2GRAY if np mean gray 127 gray 255 gray return cv2 cvtColor gray cv2 COLOR_GRAY2RGB def add_channel img lab cv2 cvtColor img cv2 COLOR_RGB2LAB clahe cv2 createCLAHE clipLimit 2.0 tileGridSize 21 21 lab clahe apply lab 0 if lab mean 127 lab 255 lab return np dstack img lab def fix_mask msk sigmoid False if not sigmoid msk 2 msk 2 127 msk 1 msk 1 127 msk 2 0 msk 0 msk 1 0 msk 2 0 else msk msk 127 return msk astype np uint8 255 def img_to_tensor im normalize None tensor torch from_numpy np moveaxis im 255. if im dtype np uint8 else 1 1 0 astype np float32 if normalize is not None return F normalize tensor normalize return tensor def mask_to_tensor mask num_classes sigmoid mask fix_mask mask sigmoid if num_classes 1 if not sigmoid #softmax long_mask np zeros mask shape 2 dtype np int64 if len mask shape 3 for c in range mask shape 2 long_mask mask c 0 c else long_mask mask 127 1 long_mask mask 0 0 mask long_mask else mask np moveaxis mask 255. if mask dtype np uint8 else 1 1 0 astype np float32 else mask np expand_dims mask 255. if mask dtype np uint8 else 1 0 astype np float32 return torch from_numpy mask\n",
      "91\n",
      "## used from xhulu  https://www.kaggle.com/xhlulu/severstal-predict-missing-masks train_df 'isNan' pd isna train_df 'EncodedPixels' train_df 'ImageId' train_df 'ImageId_ClassId' apply lambda x x split '_' 0 train_df head\n",
      "92\n",
      "train_nan_df train_df groupby by 'ImageId' axis 0 agg 'sum' train_nan_df reset_index inplace True train_nan_df rename columns 'isNan' 'missingCount' inplace True train_nan_df 'missingCount' train_nan_df 'missingCount' astype np int32 train_nan_df 'allMissing' train_nan_df 'missingCount' 4 astype int train_nan_df head\n",
      "93\n",
      "train_nan_df head\n",
      "94\n",
      "train_nan_df 'label' train_nan_df 'allMissing' apply lambda x 1 if x 0 else 0\n",
      "95\n",
      "train_nan_df drop 'missingCount' 'allMissing' axis 1 inplace True\n",
      "96\n",
      "train_nan_df label value_counts\n",
      "97\n",
      "train_df train_nan_df copy\n",
      "98\n",
      "test_df pd DataFrame\n",
      "99\n",
      "train_df head\n",
      "100\n",
      "test_df 'ImageId' np array os listdir '../input/test_images/'\n",
      "101\n",
      "test_df 'label' np array 0 1801\n",
      "102\n",
      "X_train train_df ImageId\n",
      "103\n",
      "y_train train_df label\n",
      "104\n",
      "X_test test_df ImageId\n",
      "105\n",
      "y_test test_df label\n",
      "106\n",
      "from fastai vision import from fastai callbacks import\n",
      "107\n",
      "data_folder Path \"../input\"\n",
      "108\n",
      "def _go_ben img img img 255 return cv2 addWeighted img 4 cv2 GaussianBlur img 0 0 10 4 128 go_ben TfmPixel _go_ben\n",
      "109\n",
      "test_img ImageList from_df test_df path data_folder folder 'test_images' trfm get_transforms do_flip True flip_vert True max_rotate 10.0 max_zoom 1.1 max_lighting 0.2 max_warp 0.2 p_affine 0.75 p_lighting 0.75 xtra_tfms contrast scale 0.5 1.1 p 0.75 #,go_ben(p=0.5)])\n",
      "110\n",
      "train_img_medium ImageList from_df train_df path data_folder folder 'train_images' split_by_rand_pct 0.1 label_from_df add_test test_img transform trfm size 256 600 databunch path '.' bs 16 device torch device 'cuda:0' normalize imagenet_stats train_img_small ImageList from_df train_df path data_folder folder 'train_images' split_by_rand_pct 0.1 label_from_df add_test test_img transform trfm size 128 400 databunch path '.' bs 16 device torch device 'cuda:0' normalize imagenet_stats\n",
      "111\n",
      "train_img_small show_batch rows 3 figsize 12 9\n",
      "112\n",
      "from torch import nn import torch nn functional as F class FocalLoss nn Module def __init__ self alpha 1. gamma 2. super __init__ self alpha alpha self gamma gamma def forward self inputs targets kwargs CE_loss nn CrossEntropyLoss reduction 'none' inputs targets pt torch exp CE_loss F_loss self alpha 1 pt self gamma CE_loss return F_loss mean\n",
      "113\n",
      "### Yet to be implemented  learn_densenet201 cnn_learner train_img_small models densenet201 metrics accuracy model_dir \"/tmp/model/\" learn_densenet201 loss_fn FocalLoss\n",
      "114\n",
      "learn_resnet50 cnn_learner train_img_small models resnet50 metrics accuracy model_dir \"/tmp/model/\" learn_resnet50 loss_fn FocalLoss\n",
      "115\n",
      "learn_resnet50 lr_find learn_resnet50 recorder plot suggestion True\n",
      "116\n",
      "learn_resnet50 fit_one_cycle 5 max_lr slice 2e-3\n",
      "117\n",
      "learn_resnet50 data train_img_medium learn_resnet50 loss_fn FocalLoss learn_resnet50 unfreeze learn_resnet50 lr_find learn_resnet50 recorder plot suggestion True\n",
      "118\n",
      "learn_resnet50 fit_one_cycle 20 max_lr slice 3e-4 callbacks SaveModelCallback learn_resnet50 every 'improvement' monitor 'accuracy' name 'best' mixup\n",
      "119\n",
      "interp ClassificationInterpretation from_learner learn_resnet50 interp plot_confusion_matrix interp plot_top_losses 9 figsize 15 15 heatmap True\n",
      "120\n",
      "preds y learn_resnet50 TTA ds_type DatasetType Test\n",
      "121\n",
      "test_df 'prediction' preds numpy 0\n",
      "122\n",
      "test_df head 20\n",
      "123\n",
      "os listdir '../input/test_images/'\n",
      "124\n",
      "img cv2 imread '../input/test_images/fc3c8279e.jpg' 1 img cv2 cvtColor img cv2 COLOR_BGR2RGB plt imshow img\n",
      "125\n",
      "test_final test_df loc test_df 'prediction' 0.50\n",
      "126\n",
      "test_final describe\n",
      "127\n",
      "test_df\n",
      "128\n",
      "test_final to_csv 'filtered_test_no_defect.csv'\n",
      "129\n",
      "test_final describe\n",
      "130\n",
      "How many classes do each image have?\n",
      "131\n",
      "images with defect(contain 3 type label)\n",
      "132\n",
      "\n",
      "There are similar numbers of images with and without defects.\n",
      "class is imbalanced\n",
      "\n",
      "133\n",
      "Let's visualization masks!\n",
      "134\n",
      "images with defect(label: 4)\n",
      "135\n",
      "Start Classification Process\n",
      "136\n",
      "check image data\n",
      "image size\n",
      "137\n",
      "images with defect(label: 1)\n",
      "138\n",
      "images with defect(label: 2)\n",
      "139\n",
      "Augmentation functions in one place . Will use later . Not now\n",
      "140\n",
      "Images with normal mask and Ben's processing\n",
      "141\n",
      "images with defect(contain multi label)\n",
      "142\n",
      "Multiple Images with Ben's preprocessing\n",
      "143\n",
      "Reference :http://faculty.neu.edu.cn/yunhyan/NEU_surface_defect_database.html\n",
      "In the Northeastern University (NEU) surface defect database, six kinds of typical surface defects of the hot-rolled steel strip are collected, i.e., rolled-in scale (RS), patches (Pa), crazing (Cr), pitted surface (PS), inclusion (In) and scratches (Sc). \n",
      " #### At a first look it seems for our images :\n",
      "1. Class 1 : Inclusion\n",
      "2. Class 2: Pitted\n",
      "3. Class 3 : Scratches \n",
      "4. Class 4 : Patches . \n",
      "However I  might be wrong :) . \n",
      "\n",
      "144\n",
      "Note : This Kernel is a Fork from the amazing Kernel below . So please upvote the original Kernel . I have started adding few information and preprocessing into this on my own .\n",
      "https://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda\n",
      "145\n",
      "images with defect(label: 3)\n",
      "146\n",
      "\n",
      "All image have same shape, (1600, 256).\n",
      "\n",
      "147\n",
      "Start with binary classification here\n",
      "148\n",
      "About The Competition : Detecting Steel Defect\n",
      "Steel is one of the most important building materials of modern times. Steel buildings are resistant to natural and man-made wear which has made the material ubiquitous around the world. To help make production of steel more efficient, this competition will help identify defects.\n",
      "Severstal is leading the charge in efficient steel mining and production. They believe the future of metallurgy requires development across the economic, ecological, and social aspects of the industry—and they take corporate responsibility seriously. The company recently created the country’s largest industrial data lake, with petabytes of data that were previously discarded. Severstal is now looking to machine learning to improve automation, increase efficiency, and maintain high quality in their production.\n",
      "The production process of flat sheet steel is especially delicate. From heating and rolling, to drying and cutting, several machines touch flat steel by the time it’s ready to ship. Today, Severstal uses images from high frequency cameras to power a defect detection algorithm.\n",
      "In this competition, you’ll help engineers improve the algorithm by localizing and classifying surface defects on a steel sheet.\n",
      "If successful, you’ll help keep manufacturing standards for steel high and enable Severstal to continue their innovation, leading to a stronger, more efficient world all around us.\n",
      "149\n",
      "import modules and define models\n",
      "150\n",
      "\n",
      "almost image have no defect or one kind of defect\n",
      "\n",
      "151\n",
      "import pandas as pd import numpy as np import matplotlib pyplot as plt import seaborn as sns import warnings as ws ws filterwarnings \"ignore\"\n",
      "152\n",
      "df pd read_csv \"/kaggle/input/us-police-shootings/shootings.csv\"\n",
      "153\n",
      "df head\n",
      "154\n",
      "df isna sum\n",
      "155\n",
      "sns set sns countplot df \"gender\" plt title \"The Gender of Killed Person\" plt show\n",
      "156\n",
      "avg_age_of_person df age mean print avg_age_of_person\n",
      "157\n",
      "# status of arming  temp df armed value_counts sort_values ascending False reset_index\n",
      "158\n",
      "sns barplot x \"index\" y \"armed\" data temp temp \"armed\" 50 plt show\n",
      "159\n",
      "plt figure figsize 20 20 sns barplot y \"index\" x \"state\" data df state value_counts reset_index plt title \"State wise count for the killing criminals\" plt show\n",
      "160\n",
      "sns countplot df signs_of_mental_illness plt title \"Status of mental illness\" plt show\n",
      "161\n",
      "sns barplot x \"arms_category\" y \"index\" data df arms_category value_counts reset_index plt show\n",
      "162\n",
      "Most of them were armed by the gun \n",
      "163\n",
      "Upvote it if you find it useful :)\n",
      "164\n",
      "# This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here's several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only \"../input/\" directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname _ filenames in os walk '/kaggle/input' for filename in filenames print os path join dirname filename # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"  # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
      "165\n",
      "import matplotlib as mlp import matplotlib pyplot as plt import numpy as np # plot simple sin & cos function plt style use 'classic' x np linspace 1 10 200 plt plot x np sin x plt plot x np cos x plt show # plt.show() starts an event loop, looks for all currently active figure objects,and opens one or more interactive windows that display your figure or figures.\n",
      "166\n",
      "matplotlib\n",
      "167\n",
      "x np linspace 0 10 100 fig plt figure plt plot x np sin x '_' plt plot x np cos x '_' fig savefig 'my_figure.png'\n",
      "168\n",
      "fig canvas get_supported_filetypes\n",
      "169\n",
      "# one more way to draw graph plt figure # create the first of two panels and set current axis plt subplot 2 1 1 # (rows, columns, panel number) plt plot x np sin x # create the second panel and set current axis plt subplot 2 1 2 plt plot x np cos x\n",
      "170\n",
      "# Simple Line Plots # Perhaps the simplest of all plots is the visualization of a single function y = f(x) . Here we will take a first look at creating a simple plot of this type. As with all the following # sections, we’ll start by setting up the notebook for plotting and importing the func‐ tions we will use: matplotlib inline import matplotlib pyplot as plt plt style use 'seaborn-whitegrid' import numpy as np # For all Matplotlib plots, we start by creating a figure and an axes. In their simplest form, a figure and axes can be created as follows fig plt figure ax plt axis # Once we have created an axes, we can use the ax.plot function to plot some data. Let’s start with a simple sinusoid x np linspace 1 10 1000 x np linspace 0 10 2000 plt plot x np sin x # If we want to create a single figure with multiple lines, we can simply call the plot function multiple times plt plot x np sin x plt plot x np cos x # plt.plot(x, np.tan(x))\n",
      "171\n",
      "# Adjusting the Plot: Line Colors and Styles # The first adjustment you might wish to make to a plot is to control the line colors and styles. The plt.plot() function takes additional arguments that can be used to spec‐ # ify these. To adjust the color, you can use the color keyword, which accepts a string argument representing virtually any imaginable color. The color can be specified in a variety of ways plt plot x np sin x 0 color 'blue' # specify color by name plt plot x np sin x 1 color 'g' # short color code (rgbcmyk) plt plot x np sin x 2 color '0.75' # Grayscale between 0 and 1 plt plot x np sin x 3 color '#FFDD44' # Hex code (RRGGBB from 00 to FF) plt plot x np sin x 4 color 1.0 0.2 0.3 # RGB tuple, values 0 and 1 plt plot x np sin x 5 color 'chartreuse' # all HTML color names supported # If no color is specified, Matplotlib will automatically cycle through a set of default colors for multiple lines. # Similarly, you can adjust the line style using the linestyle keyword plt plot x x 0 linestyle 'solid' plt plot x x 1 linestyle 'dashed' plt plot x x 2 linestyle 'dashdot' plt plot x x 3 linestyle 'dotted' # For short, you can use the following codes: plt plot x x 4 linestyle '-' # solid plt plot x x 5 linestyle '--' # dashed plt plot x x 6 linestyle '-.' # dashdot plt plot x x 7 linestyle ':' # dotted\n",
      "172\n",
      "# If you would like to be extremely terse, these linestyle and color codes can be com‐ bined into a single nonkeyword argument to the plt.plot() function plt plot x x 0 '-g' # solid green  # x & x+1 is drawing a line here plt plot x x 1 '--c' # dashed cyan plt plot x x 2 '-.k' # dashdot black plt plot x x 3 ':r' # dotted red # These single-character color codes reflect the standard abbreviations in the RGB (Red/Green/Blue) and CMYK (Cyan/Magenta/Yellow/blacK) color systems, com‐monly used for digital color graphics.\n",
      "173\n",
      "# Adjusting the Plot: Axes Limits # Matplotlib does a decent job of choosing default axes limits for your plot, but some‐times it’s nice to have finer control. The most basic way to adjust axis limits is to use the plt.xlim() and plt.ylim() methods plt plot x np sin x plt xlim 0 11 plt ylim 0 1.5\n",
      "174\n",
      "# If for some reason you’d like either axis to be displayed in reverse, you can simply reverse the order of the arguments plt plot x np sin x plt xlim 10 0 plt ylim 1.2 1.2\n",
      "175\n",
      "# A useful related method is plt.axis() (note here the potential confusion between axes with an e, and axis with an i). The plt.axis() method allows you to set the x # and y limits with a single call, by passing a list that specifies [xmin, xmax, ymin,ymax] plt plot x np sin x plt axis 1 11 0 6\n",
      "176\n",
      "# The plt.axis() method goes even beyond this, allowing you to do things like auto‐ matically tighten the bounds around the current plot plt plot x np sin x plt axis 'tight'\n",
      "177\n",
      "# It allows even higher-level specifications, such as ensuring an equal aspect ratio so that on your screen, one unit in x is equal to one unit in y plt plot x np sin x plt axis 'equal'\n",
      "178\n",
      "# Labeling Plots # we’ll briefly look at the labeling of plots: titles, axis labels, and simple legends. # Titles and axis labels are the simplest such labels—there are methods that can be used to quickly set them plt plot x np sin x plt title 'A sign curve' plt xlabel \"x value\" plt ylabel \"sinx value\"\n",
      "179\n",
      "# When multiple lines are being shown within a single axes, it can be useful to create a plot legend that labels each line type. # Again, Matplotlib has a built-in way of quickly creating such a legend. It is done via the (you guessed it) plt.legend() method. plt plot x np sin x 'g' label 'sin(x)' plt plot x np cos x 'r' label 'cos(x)' plt axis 'equal' plt legend # this method is responsible for displaying legend # As you can see, the plt.legend() function keeps track of the line style and color, and matches these with the correct label. More information on specifying and formatting # plot legends can be found in the plt.legend() docstring;\n",
      "180\n",
      "# In the object-oriented interface to plotting, rather than calling these functions indi‐ vidually, it is often more convenient to use the ax.set() method to set all these prop‐erties at once ax plt axes ax plot x np sin x ax set xlim 0 10 ylim 2 2 xlabel 'x' ylabel 'sin(x)' title 'A sign curve'\n",
      "181\n",
      "# Simple Scatter Plots # Another commonly used plot type is the simple scatter plot, a close cousin of the line plot. Instead of points being joined by line segments, here the points are represented individually with a dot, circle, or other shape.  matplotlib inline import matplotlib pyplot as plt plt style use 'seaborn-whitegrid' import numpy as np x np linspace 0 10 30 y np sin x plt plot x y 'o' color 'black' # The third argument in the function call is a character that represents the type of sym‐bol used for the plotting. Just as you can specify options such as '-' and '--' to con‐ # trol the line style, the marker style has its own set of short string codes. \n",
      "182\n",
      "rng np random RandomState 0 for marker in 'o' '.' ',' 'x' '+' 'v' '^' '<' '>' 's' 'd' plt plot rng rand 5 rng rand 5 marker label \"marker='{0}'\" format marker plt legend numpoints 1 plt xlim 0 1.8\n",
      "183\n",
      "# For even more possibilities, these character codes can be used together with line and color codes to plot points along with a line connecting them plt plot x y '-ok' # line (-), circle marker (o), black (k)\n",
      "184\n",
      "# Additional keyword arguments to plt.plot specify a wide range of properties of the lines and markers plt plot x y '-p' color 'gray' markersize 15 linewidth 4 markerfacecolor 'white' markeredgecolor 'gray' markeredgewidth 2 plt ylim 1.2 1.2 plt xlim 0 3\n",
      "185\n",
      "# Scatter Plots with plt.scatter plt scatter x y marker 'o'\n",
      "186\n",
      "# Let’s show this by creating a random scatter plot with points of many colors and sizes. rng np random RandomState 0 x rng randn 100 y rng randn 100 colors rng rand 100 sizes 1000 rng rand 100 plt scatter x y c colors s sizes alpha 0.3 cmap 'viridis' plt colorbar # show color scale # Notice that the color argument is automatically mapped to a color scale (shown here by the colorbar() command), and the size argument is given in pixels. In this way, # the color and size of points can be used to convey information in the visualization, in order to illustrate multidimensional data.\n",
      "187\n",
      "#  we might use the Iris data from Scikit-Learn, where each sample is one of three types of flowers that has had the size of its petals and sepals carefully measured from sklearn datasets import load_iris iris load_iris features iris data T plt scatter features 0 features 1 alpha 0.2 s 100 features 3 c iris target cmap 'viridis' plt xlabel iris feature_names 0 plt ylabel iris feature_names 1\n",
      "188\n",
      "# Basic Errorbars matplotlib inline import matplotlib pyplot as plt plt style use 'seaborn-whitegrid' import numpy as np x np linspace 0 10 50 dy 0.9 y np sin x dy np random randn 50 plt errorbar x y yerr dy fmt '.k' # Here the fmt is a format code controlling the appearance of lines and points, and has the same syntax as the shorthand used in plt.plot\n",
      "189\n",
      "# In addition to these basic options, the errorbar function has many options to finetune the outputs. Using these additional options you can easily customize the aesthet‐ics of your errorbar plot plt errorbar x y yerr dy fmt 'o' color 'black' ecolor 'lightgray' elinewidth 3 capsize 0\n",
      "190\n",
      "matplotlib inline import matplotlib pyplot as plt plt style use 'seaborn-whitegrid' import numpy as np # Visualizing a Three-Dimensional Function # We’ll start by demonstrating a contour plot using a function z = f (x, y) def f x y return np sin x 10 np cos 10 y x np cos x # A contour plot can be created with the plt.contour function. It takes three arguments: a grid of x values, a grid of y values, and a grid of z values. The x and y values # represent positions on the plot, and the z values will be represented by the contour levels.  x np linspace 0 5 60 y np linspace 0 5 50 # most straightforward way to prepare such data is to use the np.meshgrid function, which builds two-dimensional grids from one-dimensional arrays X Y np meshgrid x y Z f X Y # Now let’s look at this with a standard line-only contour plot plt contour X Y Z color 'black' # Notice that by default when a single color is used, negative values are represented by dashed lines, and positive values by solid lines.\n",
      "191\n",
      "plt contour X Y Z 20 cmap 'RdGy' # we chose the RdGy (short for Red-Gray) colormap\n",
      "192\n",
      "# Our plot is looking nicer, but the spaces between the lines may be a bit distracting. We can change this by switching to a filled contour plot using the plt.contourf() # function (notice the f at the end), which uses largely the same syntax as plt.contour() plt contourf X Y Z 20 cmap 'RdGy' plt colorbar # The colorbar makes it clear that the black regions are “peaks,” while the red regions are “valleys.”\n",
      "193\n",
      "# A better way to handle this is to use the plt.imshow() function, which inter‐prets a two-dimensional grid of data as an image. plt imshow Z extent 0 5 0 5 origin 'lower' cmap 'RdGy' plt colorbar plt axis aspect 'image'\n",
      "194\n",
      "# Finally, it can sometimes be useful to combine contour plots and image plots. For example, to create the effect shown in Figure 4-34, we’ll use a partially transparent # background image (with transparency set via the alpha parameter) and over-plot contours with labels on the contours themselves (using the plt.clabel() function contours plt contour X Y Z 3 color 'black' plt clabel contours inline True fontsize 8 plt imshow Z extent 0 5 0 5 origin 'lower' cmap 'RdGy' alpha 0.5 plt colorbar # The combination of these three functions—plt.contour, plt.contourf, and plt.imshow—gives nearly limitless possibilities for displaying this sort of threedimensional data within a two-dimensional plot.\n",
      "195\n",
      "# A simple histogram can be a great first step in understanding a dataset. Earlier, we saw a preview of Matplotlib’s histogram function matplotlib inline import matplotlib pyplot as plt import numpy as np plt style use 'seaborn-white' data np random randn 1000 plt hist data\n",
      "196\n",
      "# The hist() function has many options to tune both the calculation and the display; here’s an example of a more customized histogram plt hist data bins 30 alpha 1 histtype 'stepfilled' color 'red' edgecolor 'none' # The plt.hist docstring has more information on other customization options avail‐ able. I find this combination of histtype='stepfilled' along with some transpar‐ # ency alpha to be very useful when comparing histograms of several distributions\n",
      "197\n",
      "x1 np random normal 0 0.8 1000 x2 np random normal 1 2 1000 x3 np random normal 3 4 1000 test dict histtype 'stepfilled' alpha 0.3 bins 40 plt hist x1 test plt hist x2 test plt hist x3 test\n",
      "198\n",
      "# If you would like to simply compute the histogram (that is, count the number of points in a given bin) and not display it, the np.histogram() function is available counts bin_edges np histogram data bins 5 print counts\n",
      "199\n",
      "# Two-Dimensional Histograms and Binnings # Just as we create histograms in one dimension by dividing the number line into bins, we can also create histograms in two dimensions by dividing points among twodimensional bins # We’ll start by defining some data—an x and y array drawn from a multivariate Gaussian distribution mean 0 0 cov 1 1 1 2 x y np random multivariate_normal mean cov 10000 T # plt.hist2d: Two-dimensional histogram # One straightforward way to plot a two-dimensional histogram is to use Matplotlib’s plt.hist2d function plt hist2d x y bins 30 cmap 'Blues' cb plt colorbar cb set_label 'Counts in bin'\n",
      "200\n",
      "counts xedges yedges np histogram2d x y bins 30 # For the generalization of this histogram binning in dimensions higher than two, see the np.histogramdd function\n",
      "201\n",
      "# plt.hexbin: Hexagonal binnings # The two-dimensional histogram creates a tessellation of squares across the axes. Another natural shape for such a tessellation is the regular hexagon. For this purpose, # Matplotlib provides the plt.hexbin routine, which represents a two-dimensional dataset binned within a grid of hexagons plt hexbin x y gridsize 30 cmap 'Blues' cb plt colorbar label 'count in bin' # plt.hexbin has a number of interesting options, including the ability to specify weights for each point, and to change the output in each bin to any NumPy aggregate\n",
      "202\n",
      "# Kernel density estimation # Another common method of evaluating densities in multiple dimensions is kernel density estimation (KDE) # One extremely quick and simple KDE implementation exists in the scipy.stats package. Here is a quick example of using the KDE on this data from scipy stats import gaussian_kde # fit an array of size [Ndim, Nsamples] data np vstack x y kde gaussian_kde data # evaluate on a regular grid xgrid np linspace 3.5 3.5 40 ygrid np linspace 6 6 40 Xgrid Ygrid np meshgrid xgrid ygrid Z kde evaluate np vstack Xgrid ravel Ygrid ravel # Plot the result as an image plt imshow Z reshape Xgrid shape origin 'lower' aspect 'auto' extent 3.5 3.5 6 6 cmap 'Blues' cb plt colorbar cb set_label \"density\"\n",
      "203\n",
      "# Plot legends give meaning to a visualization, assigning labels to the various plot ele‐ments. We previously saw how to create a simple legend; here we’ll take a look at cus‐ # tomizing the placement and aesthetics of the legend in Matplotlib import matplotlib pyplot as plt plt style use 'classic' matplotlib inline import numpy as np x np linspace 0 10 1000 fig ax plt subplots ax plot x np sin x 'b' label 'sine' ax plot x np cos x '--r' label 'Cosine' ax axis 'equal' leg ax legend\n",
      "204\n",
      "# But there are many ways we might want to customize such a legend. For example, we can specify the location and turn off the frame ax legend loc 'upper left' frameon 'false' fig\n",
      "205\n",
      "# We can use the ncol command to specify the number of columns in the legend ax legend frameon False loc 'lower center' ncol 2 fig\n",
      "206\n",
      "# We can use a rounded box (fancybox) or add a shadow, change the transparency (alpha value) of the frame, or change the padding around the text ax legend fancybox True framealpha 1 shadow True borderpad 1 fig\n",
      "207\n",
      "# Choosing Elements for the Legend # The plt.plot() command is able to create multiple lines at once, and returns a list of created line instances. Passing any of # these to plt.legend() will tell it which to identify, along with the labels we’d like to specify y np sin x np newaxis np pi np arange 0 2 0.5 lines plt plot x y # lines is a list of plt.Line2D instances plt legend lines 2 'first' 'second'\n",
      "208\n",
      "# I generally find in practice that it is clearer to use the first method, applying labels to the plot elements you’d like to show on the legend plt plot x y 0 label 'first' plt plot x y 1 label 'second' plt plot x y 2 plt legend framealpha 1 frameon True\n",
      "209\n",
      "# Multiple Legends # creating a new legend artist from scratch, and then using the lower-level ax.add_artist() method to manually add the second artist to the plot fig ax plt subplots lines styles '-' '--' '-.' ':' x np linspace 0 10 1000 for i in range 4 lines ax plot x np sin x i np pi 2 styles i color 'black' ax axis 'equal' # specify the lines and labels of the first legend ax legend lines 2 'line A' 'line B' loc 'upper right' frameon False # Create the second legend and add the artist manually. from matplotlib legend import Legend leg Legend ax lines 2 'line C' 'line D' loc 'lower right' frameon False ax add_artist leg\n",
      "210\n",
      "# Customizing Colorbars import matplotlib pyplot as plt plt style use 'classic' matplotlib inline import numpy as np # As we have seen several times throughout this section, the simplest colorbar can be created with the plt.colorbar function  x np linspace 0 10 1000 I np sin x np cos x np newaxis plt imshow I plt colorbar\n",
      "211\n",
      "# We can specify the colormap using the cmap argument to the plotting function that is creating the visualization plt imshow I cmap 'gray'\n",
      "212\n",
      "from matplotlib colors import LinearSegmentedColormap def grayscale_cmap cmap \"\"\"Return a grayscale version of the given colormap\"\"\" cmap plt cm get_cmap cmap colors cmap np arange cmap N # convert RGBA to perceived grayscale luminance # cf. http://alienryderflex.com/hsp.html RGB_weight 0.299 0.587 0.114 luminance np sqrt np dot colors 3 2 RGB_weight colors 3 luminance np newaxis return LinearSegmentedColormap from_list cmap name \"_gray\" colors cmap N\n",
      "213\n",
      "def view_colormap cmap \"\"\"Plot a colormap with its grayscale equivalent\"\"\" cmap plt cm get_cmap cmap colors cmap np arange cmap N cmap grayscale_cmap cmap grayscale cmap np arange cmap N fig ax plt subplots 2 figsize 6 2 subplot_kw dict xticks yticks ax 0 imshow colors extent 0 10 0 1 ax 1 imshow grayscale extent 0 10 0 1 view_colormap 'jet'\n",
      "214\n",
      "# Color limits and extensions # Matplotlib allows for a large range of colorbar customization. The colorbar itself is simply an instance of plt.Axes, so all of the axes and tick formatting tricks we’ve # learned are applicable. The colorbar has some interesting flexibility; for example, we can narrow the color limits and indicate the out-of-bounds values with a triangular # arrow at the top and bottom by setting the extend property. This might come in handy\n",
      "215\n",
      "# make noise in 1% of the image pixels speckles np random random I shape 0.01 I speckles np random normal 0 3 np count_nonzero speckles plt figure figsize 10 3.5 plt subplot 1 2 1 plt imshow I cmap 'RdBu' plt colorbar plt subplot 1 2 2 plt imshow I cmap 'RdBu' plt colorbar extend 'both' plt clim 1 1\n",
      "216\n",
      "# Discrete colorbars # Colormaps are by default continuous, but sometimes you’d like to represent discrete values. The easiest way to do this is to use the plt.cm.get_cmap() function, and pass # the name of a suitable colormap along with the number of desired bins plt imshow I cmap plt cm get_cmap 'Blues' 6 plt colorbar plt clim 1 1\n",
      "217\n",
      "# Example: Handwritten Digits  # load images of the digits 0 through 5 and visualize several of them from sklearn datasets import load_digits digits load_digits n_class 6 fig ax plt subplots 8 8 figsize 6 6 for i axi in enumerate ax flat axi imshow digits images i cmap 'binary' axi set xticks yticks\n",
      "218\n",
      "## project the digits into 2 dimensions using IsoMap from sklearn manifold import Isomap iso Isomap n_components 2 projection iso fit_transform digits data # plot the results plt scatter projection 0 projection 1 lw 0.1 c digits target cmap plt cm get_cmap 'cubehelix' 6 plt colorbar ticks range 6 label 'digit value' plt clim 0.5 5.5\n",
      "219\n",
      "matplotlib inline import matplotlib pyplot as plt plt style use 'seaborn-white' import numpy as np # plt.axes: Subplots by Hand ax1 plt axes # standard axes ax2 plt axes 0.65 0.65 0.2 0.2\n",
      "220\n",
      "# The equivalent of this command within the object-oriented interface is fig.add_axes(). Let’s use this to create two vertically stacked axes fig plt figure ax1 fig add_axes 0.1 0.5 0.8 0.4 xticklabels ylim 1.2 1.2 ax2 fig add_axes 0.1 0.1 0.8 0.4 ylim 1.2 1.2 x np linspace 0 10 ax1 plot np sin x ax2 plot np cos x\n",
      "221\n",
      "# plt.subplot: Simple Grids of Subplots for i in range 1 7 plt subplot 2 3 i plt text 0.5 0.5 str 2 3 i fontsize 18 ha 'center'\n",
      "222\n",
      "# The command plt.subplots_adjust can be used to adjust the spacing between these plots. fig plt figure fig subplots_adjust hspace 0.4 wspace 0.4 for i in range 1 7 ax fig add_subplot 2 3 i ax text 0.5 0.5 str 2 3 i fontsize 18 ha 'center'\n",
      "223\n",
      "# plt.subplots: The Whole Grid in One Go # Here we’ll create a 2×3 grid of subplots, where all axes in the same row share their y-axis scale, and all axes in the same column share their x-axis scale  fig ax plt subplots 2 3 sharex 'col' sharey 'row'\n",
      "224\n",
      "# # axes are in a two-dimensional array, indexed by [row, col] for i in range 2 for j in range 3 ax i j text 0.5 0.5 str i j fontsize 18 ha 'center' fig # In comparison to plt.subplot(), plt.subplots() is more consistent with Python’s conventional 0-based indexing\n",
      "225\n",
      "# plt.GridSpec: More Complicated Arrangements grid plt GridSpec 2 3 wspace 0.4 hspace 0.4 #From this we can specify subplot locations and extents using the familiar Python slic‐ing syntax  plt subplot grid 0 0 plt subplot grid 0 1 plt subplot grid 1 2 plt subplot grid 1 2\n",
      "226\n",
      "# # Create some normally distributed data # Create some normally distributed data mean 0 0 cov 1 1 1 2 x y np random multivariate_normal mean cov 3000 T # Set up the axes with gridspec fig plt figure figsize 6 6 grid plt GridSpec 4 4 hspace 0.2 wspace 0.2 main_ax fig add_subplot grid 1 1 y_hist fig add_subplot grid 1 0 xticklabels sharey main_ax x_hist fig add_subplot grid 1 1 yticklabels sharex main_ax # scatter points on the main axes main_ax plot x y 'ok' markersize 3 alpha 0.2 # histogram on the attached axes x_hist hist x 40 histtype 'stepfilled' orientation 'vertical' color 'gray' x_hist invert_yaxis y_hist hist y 40 histtype 'stepfilled' orientation 'horizontal' color 'gray' y_hist invert_xaxis\n",
      "227\n",
      "# Text and Annotation matplotlib inline import matplotlib pyplot as plt import matplotlib as mpl plt style use 'seaborn-whitegrid' import numpy as np import pandas as pd\n",
      "228\n",
      "fig ax plt subplots facecolor 'lightgray' ax axis 0 10 0 10 # transform=ax.transData is the default, but we'll specify it anyway ax text 1 5 \".Data:(1,5)\" transform ax transData ax text 0.5 0.1 \". Axes: (0.5, 0.1)\" transform ax transAxes ax text 0.2 0.2 \". Figure: (0.2, 0.2)\" transform fig transFigure ax set_ylim 6 6 ax set_xlim 0 2 fig\n",
      "229\n",
      "# Arrows and Annotation # using the plt.annotate() function. This function creates some text and an arrow, and the arrows can be very flexibly specified. matplotlib inline import matplotlib pyplot as plt fig ax plt subplots x np linspace 0 20 1000 ax plot x np cos x ax axis 'equal' ax annotate 'local maximum' xy 6.28 1 xytext 10 4 arrowprops dict facecolor 'red' shrink 5.05 ax annotate 'local minimum' xy 5 np pi 1 xytext 2 6 arrowprops dict arrowstyle \"->\" connectionstyle \"angle3,angleA=0,angleB=-90\"\n",
      "230\n",
      "# The arrow style is controlled through the arrowprops dictionary, which has numerous options available. matplotlib inline import matplotlib pyplot as plt fig ax plt subplots x np linspace 0 20 2000 ax plot x np cos x ax axis 'equal'\n",
      "231\n",
      "# Customizing Ticks #Major and Minor Ticks matplotlib inline import matplotlib pyplot as plt plt style use 'seaborn-whitegrid' import numpy as np ax plt axes xscale 'log' yscale 'log' print ax xaxis get_major_locator print ax xaxis get_minor_locator\n",
      "232\n",
      "print ax xaxis get_major_formatter print ax xaxis get_minor_formatter\n",
      "233\n",
      "# Hiding Ticks or Labels # the most common tick/label formatting operation is the act of hiding ticks or labels. We can do this using plt.NullLocator() and plt.NullFormatter() ax plt axes ax plot np random rand 50 ax yaxis set_major_locator plt NullLocator ax xaxis set_major_formatter plt NullFormatter\n",
      "234\n",
      "fig ax plt subplots 5 5 figsize 5 5 fig subplots_adjust hspace 0 wspace 0 # Get some face data from scikit-learn from sklearn datasets import fetch_olivetti_faces faces fetch_olivetti_faces images for i in range 5 for j in range 5 ax i j xaxis set_major_locator plt NullLocator ax i j yaxis set_major_locator plt NullLocator ax i j imshow faces 10 i j cmap \"bone\"\n",
      "235\n",
      "# Reducing or Increasing the Number of Ticks fig ax plt subplots 4 4 sharex True sharey True\n",
      "236\n",
      "# plt.MaxNLocator(), which allows us to specify the maximum number of ticks that will be displayed # # For every axis, set the x and y major locator for axi in ax flat axi xaxis set_major_locator plt MaxNLocator 3 axi yaxis set_major_locator plt MaxNLocator 3 fig\n",
      "237\n",
      "# Fancy Tick Formats # Plot a sine and cosine curve fig ax plt subplots x np linspace 0 3 np pi 1000 ax plot x np sin x lw 3 label 'Sine' ax plot x np cos x lw 3 label 'Cosine' # Set up grid, legend, and limits ax grid True ax legend frameon False ax axis 'equal' ax set_xlim 0 3 np pi ax xaxis set_major_locator plt MultipleLocator np pi 2 ax xaxis set_minor_locator plt MultipleLocator np pi 4 fig\n",
      "238\n",
      "def format_func value tick_number # find number of multiples of pi/2 # we’ll instead use plt.FuncFormatter, which accepts a user-defined function giving fine-grained control over the tick outputs N int np round 2 value np pi if N 0 return \"0\" elif N 1 return r\"$\\pi/2$\" elif N 2 return r\"$\\pi$\" elif N 2 0 return r\"${0}\\pi/2$\" format N else return r\"${0}\\pi$\" format N 2 ax xaxis set_major_formatter plt FuncFormatter format_func fig\n",
      "239\n",
      "# Plot Customization by Hand import matplotlib pyplot as plt plt style use 'classic' import numpy as np matplotlib inline x np random randn 1000 plt hist x # We can adjust this by hand to make it a much more visually pleasing plot # draw solid white grid lines plt grid color 'w' linestyle 'solid' # hide axis spines for spine in ax spines values spine set_visible False\n",
      "240\n",
      "#Changing the Defaults: rcParams # We’ll start by saving a copy of the current rcParams dictionary, so we can easily reset these changes in the current session IPython_default plt rcParams copy #Now we can use the plt.rc function to change some of these settings from matplotlib import cycler colors cycler 'color' '#EE6666' '#3388BB' '#9988DD' '#EECC55' '#88BB44' '#FFBBBB' plt rc 'axes' facecolor '#E6E6E6' edgecolor 'none' axisbelow True grid True prop_cycle colors plt rc 'grid' color 'w' linestyle 'solid' plt rc 'xtick' direction 'out' color 'gray' plt rc 'ytick' direction 'out' color 'gray' plt rc 'patch' edgecolor '#E6E6E6' plt rc 'lines' linewidth 2 plt hist x\n",
      "241\n",
      "for i in range 4 plt plot np random rand 10\n",
      "242\n",
      "# Stylesheets # The available styles are listed in plt.style.available plt style available 5 #The basic way to switch to a stylesheet is to call\n",
      "243\n",
      "# Let’s create a function that will make two basic types of plot: def hist_and_lines np random seed 0 fig ax plt subplots 1 2 figsize 11 4 ax 0 hist np random randn 1000 for i in range 3 ax 1 plot np random rand 10 ax 1 legend 'a' 'b' 'c' loc 'lower left'\n",
      "244\n",
      "#Default style # reset rcParams hist_and_lines\n",
      "245\n",
      "#FiveThirtyEight style with plt style context 'fivethirtyeight' hist_and_lines\n",
      "246\n",
      "# ggplot with plt style context 'ggplot' hist_and_lines\n",
      "247\n",
      "#Bayesian Methods for Hackers style with plt style context 'bmh' hist_and_lines\n",
      "248\n",
      "# Dark background with plt style context 'dark_background' hist_and_lines\n",
      "249\n",
      "# Grayscale with plt style context 'grayscale' hist_and_lines\n",
      "250\n",
      "# Seaborn style import seaborn hist_and_lines\n",
      "251\n",
      "# We enable three-dimensional plots by importing the mplot3d toolkit from mpl_toolkits import mplot3d # Once this submodule is imported, we can create a three-dimensional axes by passing the keyword projection='3d' to any of the normal axes creation routines matplotlib inline import numpy as np import matplotlib pyplot as plt fig plt figure ax plt axes projection '3d'\n",
      "252\n",
      "# Three-Dimensional Points and Lines #we can create these using the ax.plot3D and ax.scatter3D functions. ax plt axes projection '3d' # Data for a three-dimensional line zline np linspace 0 15 1000 yline np cos zline xline np sin zline ax plot3D xline yline zline 'red' ## Data for three-dimensional scattered points zdata 15 np random random 100 xdata np sin zdata 0.1 np random randn 100 ydata np cos zdata 0.1 np random randn 100 ax scatter3D xdata ydata zdata c zdata cmap 'Greens'\n",
      "253\n",
      "#Three-Dimensional Contour Plots def f x y return np sin np sqrt x 2 y 2 x np linspace 6 6 30 y np linspace 6 6 30 X Y np meshgrid x y Z f X Y fig plt figure ax plt axes projection '3d' ax contour3D X Y Z 50 cmap 'binary' ax set_xlabel 'x' ax set_ylabel 'y' ax set_zlabel 'z' #Sometimes the default viewing angle is not optimal, in which case we can use the view_init method to set the elevation and azimuthal angles.  ax view_init 60 35 fig\n",
      "254\n",
      "#Wireframes and Surface Plots fig plt figure ax plt axes projection '3d' ax plot_wireframe X Y Z color 'black' ax set_title 'wireframe'\n",
      "255\n",
      "# A surface plot is like a wireframe plot, but each face of the wireframe is a filled poly‐gon. Adding a colormap to the filled polygons can aid perception of the topology of # the surface being visualized ax plt axes projection '3d' ax plot_surface X Y Z rstride 1 cstride 1 cmap 'viridis' edgecolor 'none' ax set_title 'surface'\n",
      "256\n",
      "r np linspace 0 6 20 theta np linspace 0.9 np pi 0.8 np pi 40 r theta np meshgrid r theta X r np sin theta Y r np cos theta Z f X Y ax plt axes projection '3d' ax plot_surface X Y Z rstride 1 cstride 1 cmap 'viridis' edgecolor 'none'\n",
      "257\n",
      "# Surface Triangulations theta 2 np pi np random random 1000 r 6 np random random 1000 x np ravel r np sin theta y np ravel r np cos theta z f x y # We could create a scatter plot of the points to get an idea of the surface we’re sampling from ax plt axes projection '3d' ax scatter x y z c z cmap 'viridis' linewidth 0.5\n",
      "258\n",
      "# The function that will help us in this case is ax.plot_trisurf, which creates a surface by first finding a set of triangles formed # between adjacent points ax plt axes projection '3d' ax plot_trisurf x y z cmap 'viridis' edgecolor 'none'\n",
      "259\n",
      "# Example: Visualizing a Möbius strip theta np linspace 0 2 np pi 30 w np linspace 0.25 0.25 8 w theta np meshgrid w theta phi 0.5 theta # radius in x-y plane r 1 w np cos phi x np ravel r np cos theta y np ravel r np sin theta z np ravel w np sin phi\n",
      "260\n",
      "# triangulate in the underlying parameterization from matplotlib tri import Triangulation tri Triangulation np ravel w np ravel theta ax plt axes projection '3d' ax plot_trisurf x y z triangles tri triangles cmap 'viridis' linewidths 0.2 ax set_xlim 1 1 ax set_ylim 1 1 ax set_zlim 1 1\n",
      "261\n",
      "#Seaborn Versus Matplotlib import matplotlib pyplot as plt plt style use 'classic' matplotlib inline import numpy as np import pandas as pd #Now we create some random walk data: # Create some data rng np random RandomState 0 x np linspace 0 10 500 y np cumsum rng randn 500 6 0 # Plot the data with Matplotlib defaults plt plot x y plt legend 'ABCDEF' ncol 2 loc 'upper left'\n",
      "262\n",
      "import seaborn as sns sns set #Now let’s rerun the same two lines as before plt plot x y plt legend 'ABCDEF' ncol 2 loc 'upper left'\n",
      "263\n",
      "#Histograms, KDE, and densities # Often in statistical data visualization, all you want is to plot histograms and joint dis‐tributions of variables data np random multivariate_normal 0 0 5 2 2 2 size 2000 data pd DataFrame data columns 'x' 'y' for col in 'xy' plt hist data col alpha 0.5\n",
      "264\n",
      "# Rather than a histogram, we can get a smooth estimate of the distribution using a kernel density estimation, which Seaborn does with sns.kdeplot for col in 'xy' sns kdeplot data col shade True\n",
      "265\n",
      "# Histograms and KDE can be combined using distplot sns distplot data 'x' sns distplot data 'y'\n",
      "266\n",
      "# If we pass the full two-dimensional dataset to kdeplot, we will get a two-dimensional visualization of the data sns kdeplot data\n",
      "267\n",
      "# We can see the joint distribution and the marginal distributions together using sns.jointplot. For this plot, we’ll set the style to a white background with sns axes_style 'white' sns jointplot \"x\" \"y\" data kind 'kde'\n",
      "268\n",
      "# There are other parameters that can be passed to jointplot—for example, we can use a hexagonally based histogram instead with sns axes_style 'white' sns jointplot \"x\" \"y\" data kind 'hex'\n",
      "269\n",
      "# Pair plots iris sns load_dataset \"iris\" iris head\n",
      "270\n",
      "# Visualizing the multidimensional relationships among the samples is as easy as call‐ing sns.pairplot sns pairplot iris hue 'species' size 2.5\n",
      "271\n",
      "# Faceted histograms tips sns load_dataset 'tips' tips head\n",
      "272\n",
      "tips 'tip_pct' 100 tips 'tip' tips 'total_bill' grid sns FacetGrid tips row \"sex\" col \"time\" margin_titles True grid map plt hist \"tip_pct\" bins np linspace 0 40 15\n",
      "273\n",
      "# Factor plots with sns axes_style style 'ticks' g sns factorplot \"day\" \"total_bill\" \"sex\" data tips kind \"box\" g set_axis_labels \"Day\" \"Total Bill\"\n",
      "274\n",
      "# Joint distributions # Similar to the pair plot we saw earlier, we can use sns.jointplot to show the jointdistribution between different datasets, along with the associated marginal distribu‐tions with sns axes_style 'white' sns jointplot \"total_bill\" \"tip\" data tips kind 'hex'\n",
      "275\n",
      "# The joint plot can even do some automatic kernel density estimation and regression sns jointplot \"total_bill\" \"tip\" data tips kind 'reg'\n",
      "276\n",
      "# Bar plots # Time series can be plotted with sns.factorplot planets sns load_dataset 'planets' planets head\n",
      "277\n",
      "with sns axes_style 'white' g sns factorplot \"year\" data planets aspect 2 kind \"count\" color \"steelblue\" g set_xticklabels step 5\n",
      "278\n",
      "with sns axes_style 'white' g sns factorplot \"year\" data planets aspect 4.0 kind 'count' hue 'method' order range 2001 2015 g set_ylabels 'Number of Planets Discovered'\n",
      "279\n",
      "# import plotly import plotly as py from plotly offline import init_notebook_mode iplot plot init_notebook_mode connected True import plotly graph_objs as go # word cloud library from wordcloud import WordCloud\n",
      "280\n",
      "# pip install plotly==3.10.0\n",
      "281\n",
      "# Read data from input files for Seaborn Plots import numpy as np import csv as csv import pandas as pd median_house_hold_in_come pd read_csv '/kaggle/input/fatalpoliceshootingsintheus/MedianHouseholdIncome2015.csv' encoding \"windows-1252\" percentage_people_below_poverty_level pd read_csv '/kaggle/input/fatalpoliceshootingsintheus/PercentagePeopleBelowPovertyLevel.csv' encoding \"windows-1252\" percent_over_25_completed_highSchool pd read_csv '/kaggle/input/fatalpoliceshootingsintheus/PercentOver25CompletedHighSchool.csv' encoding \"windows-1252\" share_race_city pd read_csv '/kaggle/input/fatalpoliceshootingsintheus/ShareRaceByCity.csv/ShareRaceByCity.csv' encoding \"windows-1252\" kill pd read_csv '/kaggle/input/fatalpoliceshootingsintheus/PoliceKillingsUS.csv' encoding \"windows-1252\"\n",
      "282\n",
      "median_house_hold_in_come head 20\n",
      "283\n",
      "percentage_people_below_poverty_level head 20\n",
      "284\n",
      "percent_over_25_completed_highSchool head 20\n",
      "285\n",
      "share_race_city head 20\n",
      "286\n",
      "kill head 20\n",
      "287\n",
      "percentage_people_below_poverty_level 'Geographic Area' unique\n",
      "288\n",
      "# # Poverty rate of each state percentage_people_below_poverty_level replace '-' 0.0 inplace True percentage_people_below_poverty_level poverty_rate percentage_people_below_poverty_level poverty_rate astype float area_list list percentage_people_below_poverty_level 'Geographic Area' unique area_poverty_ratio for i in area_list x percentage_people_below_poverty_level percentage_people_below_poverty_level 'Geographic Area' i area_poverty_rate sum x poverty_rate len x area_poverty_ratio append area_poverty_rate data pd DataFrame 'area_list' area_list 'area_poverty_ratio' area_poverty_ratio new_index data 'area_poverty_ratio' sort_values ascending False index values sorted_data data reindex new_index # visualization plt figure figsize 15 10 sns barplot x sorted_data 'area_list' y sorted_data 'area_poverty_ratio' plt xticks rotation 45 plt xlabel 'states' plt ylabel 'Poverty Rate' plt title 'Poverty Rate Given States'\n",
      "289\n",
      "kill head\n",
      "290\n",
      "kill name value_counts\n",
      "291\n",
      "percent_over_25_completed_highSchool info\n",
      "292\n",
      "# High school graduation rate of the population that is older than 25 in states percent_over_25_completed_highSchool percent_completed_hs replace '-' 0.0 inplace True percent_over_25_completed_highSchool percent_completed_hs percent_over_25_completed_highSchool percent_completed_hs astype float area_list list percent_over_25_completed_highSchool 'Geographic Area' unique area_highschool for i in area_list x percent_over_25_completed_highSchool percent_over_25_completed_highSchool 'Geographic Area' i area_highschool_rate sum x percent_completed_hs len x area_highschool append area_highschool_rate # sorting data pd DataFrame 'area_list' area_list 'area_highschool_ratio' area_highschool new_index data 'area_highschool_ratio' sort_values ascending True index values sorted_data2 data reindex new_index # visualization plt figure figsize 15 10 sns barplot x sorted_data2 'area_list' y sorted_data2 'area_highschool_ratio' plt xticks rotation 90 plt xlabel 'States' plt ylabel 'High School Graduate Rate' plt title \"Percentage of Given State's Population Above 25 that Has Graduated High School\"\n",
      "293\n",
      "percentage_people_below_poverty_level head\n",
      "294\n",
      "percentage_people_below_poverty_level info\n",
      "295\n",
      "percentage_people_below_poverty_level 'Geographic Area' unique\n",
      "296\n",
      "share_race_city head\n",
      "297\n",
      "# Percentage of state's population according to races that are black,white,native american, asian and hispanic share_race_city replace '-' 0.0 inplace True share_race_city replace '(X)' 0.0 inplace True share_race_city loc 'share_white' 'share_black' 'share_native_american' 'share_asian' 'share_hispanic' share_race_city loc 'share_white' 'share_black' 'share_native_american' 'share_asian' 'share_hispanic' astype float area_list list share_race_city 'Geographic area' unique share_white share_black share_native_american share_asian share_hispanic for i in area_list x share_race_city share_race_city 'Geographic area' i share_white append sum x share_white len x share_black append sum x share_black len x share_native_american append sum x share_native_american len x share_asian append sum x share_asian len x share_hispanic append sum x share_hispanic len x # Visualization f ax plt subplots figsize 9 15 sns barplot x share_white y area_list color 'green' alpha 0.5 label 'White' sns barplot x share_black y area_list color 'blue' alpha 0.7 label 'African American' sns barplot x share_native_american y area_list color 'cyan' alpha 0.6 label 'Native American' sns barplot x share_asian y area_list color 'yellow' alpha 0.6 label 'Asian' sns barplot x share_hispanic y area_list color 'red' alpha 0.6 label 'Hispanic' ax legend loc 'lower right' frameon True ax set xlabel 'Percentage of Races' ylabel 'States' title \"Percentage of State's Population According to Races \"\n",
      "298\n",
      "# high school graduation rate vs Poverty rate of each state sorted_data 'area_poverty_ratio' sorted_data 'area_poverty_ratio' max sorted_data 'area_poverty_ratio' sorted_data2 'area_highschool_ratio' sorted_data2 'area_highschool_ratio' max sorted_data2 'area_highschool_ratio' data pd concat sorted_data sorted_data2 'area_highschool_ratio' axis 1 data sort_values 'area_poverty_ratio' inplace True # visualize f ax1 plt subplots figsize 20 10 sns pointplot x 'area_list' y 'area_poverty_ratio' data data color 'lime' alpha 0.8 sns pointplot x 'area_list' y 'area_highschool_ratio' data data color 'red' alpha 0.8 plt text 40 0.6 'high school graduate ratio' color 'red' fontsize 17 style 'italic' plt text 40 0.55 'poverty ratio' color 'lime' fontsize 18 style 'italic' plt xlabel 'States' fontsize 15 color 'blue' plt ylabel 'Values' fontsize 15 color 'blue' plt title 'High School Graduate  VS  Poverty Rate' fontsize 20 color 'blue' plt grid\n",
      "299\n",
      "data head\n",
      "300\n",
      "# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code # pearsonr= if it is 1, there is positive correlation and if it is, -1 there is negative correlation. # If it is zero, there is no correlation between variables # Show the joint distribution using kernel density estimation sns jointplot data area_poverty_ratio data area_highschool_ratio plt savefig 'graph.png' plt show\n",
      "301\n",
      "data head\n",
      "302\n",
      "# you can change parameters of joint plot # kind : { “scatter” | “reg” | “resid” | “kde” | “hex” } # Different usage of parameters but same plot with previous one g sns jointplot \"area_poverty_ratio\" \"area_highschool_ratio\" data data size 5 ratio 3 color \"r\"\n",
      "303\n",
      "kill race head\n",
      "304\n",
      "kill race value_counts\n",
      "305\n",
      "# Race rates according in kill data  kill race dropna inplace True labels kill race value_counts index colors 'grey' 'blue' 'red' 'yellow' 'green' 'brown' explode 0 0 0 0 0 0 sizes kill race value_counts values # visual plt figure figsize 7 7 plt pie sizes explode explode labels labels colors colors autopct '%1.1f%%' plt title 'Killed People According to Races' color 'blue' fontsize 15\n",
      "306\n",
      "data head\n",
      "307\n",
      "# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code # lmplot  # Show the results of a linear regression within each dataset sns lmplot x \"area_poverty_ratio\" y \"area_highschool_ratio\" data data plt show\n",
      "308\n",
      "data head\n",
      "309\n",
      "# Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code # cubehelix plot sns kdeplot data area_poverty_ratio data area_highschool_ratio shade True cut 3 plt show\n",
      "310\n",
      "data head\n",
      "311\n",
      "# Show each distribution with both violins and points # Use cubehelix to get a custom sequential palette pal sns cubehelix_palette 2 rot .6 dark .4 sns violinplot data data palette pal inner \"points\" plt show\n",
      "312\n",
      "data corr\n",
      "313\n",
      "#correlation map # Visualization of high school graduation rate vs Poverty rate of each state with different style of seaborn code f ax plt subplots figsize 5 10 sns heatmap data corr annot True linewidths 0.8 linecolor \"blue\" fmt '.1f' ax ax plt show\n",
      "314\n",
      "kill head\n",
      "315\n",
      "kill manner_of_death unique\n",
      "316\n",
      "sns boxplot x \"gender\" y \"age\" hue \"manner_of_death\" data kill palette \"PRGn\" plt show\n",
      "317\n",
      "sns swarmplot x \"gender\" y \"age\" hue \"manner_of_death\" data kill plt show\n",
      "318\n",
      "data head\n",
      "319\n",
      "sns pairplot data plt show\n",
      "320\n",
      "kill gender value_counts\n",
      "321\n",
      "kill head\n",
      "322\n",
      "# kill properties # Manner of death sns countplot kill gender\n",
      "323\n",
      "# kill weapon armed kill armed value_counts #print(armed) plt figure figsize 10 7 sns barplot x armed 7 index y armed 7 values plt ylabel 'Number of Weapon' plt xlabel 'Weapon Types' plt title 'Kill weapon' color 'blue' fontsize 15\n",
      "324\n",
      "# Race of killed people kill race value_counts sns countplot data kill x 'race' plt title 'Race of killed people' color 'blue' fontsize 15\n",
      "325\n",
      "# Most dangerous cities city kill city value_counts plt figure figsize 12 8 sns barplot x city 12 index y city 12 values plt xticks rotation 60 plt title 'Most dangerous cities' color 'red' fontsize 20\n",
      "326\n",
      "# most dangerous states state kill state value_counts plt figure figsize 10 7 sns barplot x state 20 index y state 20 values plt title 'Most dangerous state' color 'blue' fontsize 15\n",
      "327\n",
      "# plotly # import plotly.plotly as py from plotly offline import init_notebook_mode iplot plot import plotly as py init_notebook_mode connected True import plotly graph_objs as go # word cloud library from wordcloud import WordCloud\n",
      "328\n",
      "# Read data from input files for Plotly Plots import numpy as np import csv as csv import pandas as pd #educational_attainment_supplementary_data = pd.read_csv(\"/kaggle/input/worlduniversityrankings-data/educational_attainment_supplementary_data.csv\") cwurData pd read_csv '/kaggle/input/worlduniversityrankings-data/cwurData.csv' #education_expenditure_supplementary_data = pd.read_csv(\"/kaggle/input/worlduniversityrankings-data/education_expenditure_supplementary_data.csv\") school_and_country_table pd read_csv '/kaggle/input/worlduniversityrankings-data/school_and_country_table.csv' shanghaiData pd read_csv '/kaggle/input/worlduniversityrankings-data/shanghaiData.csv' timesData pd read_csv '/kaggle/input/worlduniversityrankings-data/timesData.csv'\n",
      "329\n",
      "timesData head 20\n",
      "330\n",
      "timesData info\n",
      "331\n",
      "# prepare data frame df timesData iloc 100 # import graph objects as \"go\" import plotly graph_objs as go # Creating trace1 trace1 go Scatter x df world_rank y df citations mode \"lines\" name \"citations\" marker dict color 'rgba(16, 112, 2, 0.8)' text df university_name # Creating trace2 trace2 go Scatter x df world_rank y df teaching mode \"lines+markers\" name \"teaching\" marker dict color 'rgba(80, 26, 80, 0.8)' text df university_name data trace1 trace2 layout dict title 'Citation and Teaching vs World Rank of Top 100 Universities' xaxis dict title 'World Rank' ticklen 5 zeroline False fig dict data data layout layout iplot fig\n",
      "332\n",
      "# prepare data frames df2014 timesData timesData year 2014 iloc 100 df2015 timesData timesData year 2015 iloc 100 df2016 timesData timesData year 2016 iloc 100 # import graph objects as \"go\" import plotly graph_objs as go # creating trace1 trace1 go Scatter x df2014 world_rank y df2014 citations mode \"markers\" name \"2014\" marker dict color 'rgba(255, 128, 255, 0.8)' text df2014 university_name # creating trace2 trace2 go Scatter x df2015 world_rank y df2015 citations mode \"markers\" name \"2015\" marker dict color 'rgba(255, 128, 2, 0.8)' text df2015 university_name # creating trace3 trace3 go Scatter x df2016 world_rank y df2016 citations mode \"markers\" name \"2016\" marker dict color 'rgba(0, 255, 200, 0.8)' text df2016 university_name data trace1 trace2 trace3 layout dict title 'Citation vs world rank of top 100 universities with 2014, 2015 and 2016 years' xaxis dict title 'World Rank' ticklen 5 zeroline False yaxis dict title 'Citation' ticklen 5 zeroline False fig dict data data layout layout iplot fig\n",
      "333\n",
      "# prepare data frames df2014 timesData timesData year 2014 iloc 3 df2014\n",
      "334\n",
      "# prepare data frames df2014 timesData timesData year 2014 iloc 3 # import graph objects as \"go\" import plotly graph_objs as go # create trace1  trace1 go Bar x df2014 university_name y df2014 citations name \"citations\" marker dict color 'rgba(255, 174, 255, 0.5)' line dict color 'rgb(0,0,0)' width 1.5 text df2014 country # create trace2  trace2 go Bar x df2014 university_name y df2014 teaching name \"teaching\" marker dict color 'rgba(255, 255, 128, 0.5)' line dict color 'rgb(0,0,0)' width 1.5 text df2014 country data trace1 trace2 layout go Layout barmode \"group\" fig go Figure data data layout layout iplot fig\n",
      "335\n",
      "# data preparation df2016 timesData timesData year 2016 iloc 7 pie1 df2016 num_students pie1_list float each replace ',' '.' for each in df2016 num_students # str(2,4) => str(2.4) = > float(2.4) = 2.4 labels df2016 university_name # figure fig \"data\" \"values\" pie1_list \"labels\" labels \"domain\" \"x\" 0 .5 \"name\" \"Number Of Students Rates\" \"hoverinfo\" \"label+percent+name\" \"hole\" .3 \"type\" \"pie\" \"layout\" \"title\" \"Universities Number of Students rates\" \"annotations\" \"font\" \"size\" 20 \"showarrow\" False \"text\" \"Number of Students\" \"x\" 0.20 \"y\" 1 iplot fig\n",
      "336\n",
      "df2016 info\n",
      "337\n",
      "# data preparation df2016 timesData timesData year 2016 iloc 20 num_students_size float each replace ',' '.' for each in df2016 num_students international_color float each for each in df2016 international data 'y' df2016 teaching 'x' df2016 world_rank 'mode' 'markers' 'marker' 'color' international_color 'size' num_students_size 'showscale' True \"text\" df2016 university_name iplot data\n",
      "338\n",
      "# prepare data x2011 timesData student_staff_ratio timesData year 2011 x2012 timesData student_staff_ratio timesData year 2012 trace1 go Histogram x x2011 opacity 0.75 name \"2011\" marker dict color 'rgba(171, 50, 96, 0.6)' trace2 go Histogram x x2012 opacity 0.75 name \"2012\" marker dict color 'rgba(12, 50, 196, 0.6)' data trace1 trace2 layout go Layout barmode 'overlay' title ' students-staff ratio in 2011 and 2012' xaxis dict title 'students-staff ratio' yaxis dict title 'Count' fig go Figure data data layout layout iplot fig\n",
      "339\n",
      "# data prepararion x2011 timesData country timesData year 2011 plt subplots figsize 8 8 wordcloud WordCloud background_color 'white' width 512 height 384 generate \" \" join x2011 plt imshow wordcloud plt axis 'off' plt savefig 'graph.png' plt show\n",
      "340\n",
      "# data preparation x2015 timesData timesData year 2015 trace0 go Box y x2015 total_score name 'total score of universities in 2015' marker dict color 'rgb(12, 12, 140)' trace1 go Box y x2015 research name 'research of universities in 2015' marker dict color 'rgb(12, 128, 128)' data trace0 trace1 iplot data\n",
      "341\n",
      "# import figure factory import plotly figure_factory as ff # prepare data dataframe timesData timesData year 2015 data2015 dataframe loc \"research\" \"international\" \"total_score\" data2015 \"index\" np arange 1 len data2015 1 # scatter matrix fig ff create_scatterplotmatrix data2015 diag 'box' index 'index' colormap 'Portland' colormap_type 'cat' height 750 width 750 iplot fig\n",
      "342\n",
      "Table of Contents\n",
      "\n",
      "Section  1 - Importing matplotlib & Classic Graph \n",
      "Section 2 - loading from a script\n",
      "Section 3 - Adjusting the Plot: Line Colors and Styles\n",
      "Section 4 - Simple Scatter Plots\n",
      "Section 5 - Visualizing Errors Density and Contour Plots\n",
      "Section 6 - Histograms, Binnings, and Density\n",
      "Section 7 - Customizing Plot Legends\n",
      "Section 8 - Multiple Subplots\n",
      "Section 9 - Multiple Plots\n",
      "Section 10 - Text & Annotation/Text Position/Arrow Position\n",
      "Section 11 - Customizing Matplotlib: Configurations and Stylesheets\n",
      "Section 12 - Three-Dimensional Plotting in Matplotlib\n",
      "Section 13 - Visualization with Seaborn\n",
      "Section 14 - Visualization with Plotly\n",
      "Section 15 - Read data from input files for Seaborn Plots\n",
      "Section 16 - Bar Plot using Seaborn\n",
      "Section 17 - Point Plot using Seaborn\n",
      "Section 18 - Joint Plot using Seaborn\n",
      "Section 19 - Pie Plot using Seaborn\n",
      "Section 20 - Lm Plot using Seaborn\n",
      "Section 21 - Kde Plot using Seaborn\n",
      "Section 22 - Violin Plot using Seaborn\n",
      "Section 23 - Heatmap\n",
      "Section 24 - Box plot\n",
      "Section 25 - Swarm Plot\n",
      "Section 26 - Pair Plot\n",
      "Section 27 - Count Plot\n",
      "Section 28 - Read data from input files for Plotly Plots\n",
      "Section 29 - Line Charts Plotly Plots\n",
      "Section 30 - Scatter Charts Plotly Plots\n",
      "Section 31 - Bar Charts Plotly Plots\n",
      "Section 32 - Pie Charts Plotly Plots\n",
      "Section 33 - Bubble Charts Plotly Plots\n",
      "Section 34 - Histogram Plotly Plots\n",
      "Section 35 - Word Cloud Plotly Plots\n",
      "Section 36 - Box Plots Plotly Plots\n",
      "Section 37 - Scatter Matrix Plotly Plots\n",
      "\n",
      "343\n",
      "Now let’s take a look at how it works with Seaborn. As we will see, Seaborn has many\n",
      "of its own high-level plotting routines, but it can also overwrite Matplotlib’s default\n",
      "parameters and in turn get even simple Matplotlib scripts to produce vastly superior\n",
      "output. We can set the style by calling Seaborn’s set() method. By convention, Sea‐\n",
      "born is imported as sns\n",
      "344\n",
      "\n",
      "Section 16 - Bar Plot using Seaborn\n",
      "345\n",
      "\n",
      "Section 26 - Pair Plot\n",
      "346\n",
      "\n",
      "Section 24 - Box plot\n",
      "347\n",
      "Sometimes it is useful to display three-dimensional data in two dimensions using\n",
      "contours or color-coded regions. There are three Matplotlib functions that can be\n",
      "helpful for this task: plt.contour for contour plots, plt.contourf for filled contour\n",
      "plots, and plt.imshow for showing images.\n",
      "348\n",
      "\n",
      "Section 15 - Read data from input files for Seaborn Plots\n",
      "349\n",
      "\n",
      "Section 13 - Visualization with Seaborn\n",
      "350\n",
      "\n",
      "Section 8 - Multiple Subplots\n",
      "351\n",
      "The most basic method of creating an axes is to use the plt.axes function. As we’ve\n",
      "seen previously, by default this creates a standard axes object that fills the entire fig‐\n",
      "ure. plt.axes also takes an optional argument that is a list of four numbers in the\n",
      "figure coordinate system. These numbers represent [bottom, left, width,\n",
      "height] in the figure coordinate system, which ranges from 0 at the bottom left of the\n",
      "figure to 1 at the top right of the figure.\n",
      "For example, we might create an inset axes at the top-right corner of another axes by\n",
      "setting the x and y position to 0.65 (that is, starting at 65% of the width and 65% of\n",
      "the height of the figure) and the x and y extents to 0.2 (that is, the size of the axes is\n",
      "20% of the width and 20% of the height of the figure). \n",
      "352\n",
      "\n",
      "Section 19 - Pie Plot using Seaborn\n",
      "353\n",
      "\n",
      "Section 3 - Adjusting the Plot: Line Colors and Styles\n",
      "354\n",
      "\n",
      "Section 31 - Bar Charts Plotly Plots\n",
      "355\n",
      "\n",
      "Section 32 - Pie Charts Plotly Plots\n",
      "356\n",
      "\n",
      "Section 20 - Lm Plot using Seaborn\n",
      "357\n",
      "\n",
      "Section 23 - Heatmap\n",
      "358\n",
      "\n",
      "Section 9 - Multiple Plots\n",
      "359\n",
      "\n",
      "Section 34 - Histogram Plotly Plots\n",
      "360\n",
      "\n",
      "Section 37 - Scatter Matrix Plotly Plots\n",
      "361\n",
      "\n",
      "Section 21 - Kde Plot using Seaborn\n",
      "362\n",
      "\n",
      "Section 7 - Customizing Plot Legends\n",
      "363\n",
      "There are a few potential gotchas with imshow(), however:\n",
      "• plt.imshow() doesn’t accept an x and y grid, so you must manually specify the\n",
      "extent [xmin, xmax, ymin, ymax] of the image on the plot.\n",
      "• plt.imshow() by default follows the standard image array definition where the\n",
      "origin is in the upper left, not in the lower left as in most contour plots. This\n",
      "must be changed when showing gridded data.\n",
      "• plt.imshow() will automatically adjust the axis aspect ratio to match the input\n",
      "data; you can change this by setting, for example, plt.axis(aspect='image') to\n",
      "make x and y units match.\n",
      "364\n",
      "\n",
      "Section 35 - Word Cloud Plotly Plots\n",
      "365\n",
      "\n",
      "Section 4 - Simple Scatter Plots\n",
      "366\n",
      "\n",
      "Section 27 - Count Plot\n",
      "367\n",
      "\n",
      "Section 6 - Histograms, Binnings, and Density\n",
      "368\n",
      "\n",
      "Section 22 - Violin Plot using Seaborn\n",
      "369\n",
      "Plotting from an IPython shell\n",
      "It can be very convenient to use Matplotlib interactively within an IPython shell. IPython is built to work well with Matplotlib if you specify Matplotlib\n",
      "mode. To enable this mode, you can use the %matplotlib magic command after start‐\n",
      "ing ipython:\n",
      "370\n",
      "\n",
      "Section 25 - Swarm Plot\n",
      "371\n",
      "\n",
      "Section  1 - Importing matplotlib & Classic Graph\n",
      "372\n",
      "\n",
      "Section 17 - Point Plot using Seaborn\n",
      "373\n",
      "Comprehensive Guide to--Matplotlib / Seaborn / Plotly\n",
      "Matplotlib is a multiplatform data visualization library built on NumPy arrays, and\n",
      "designed to work with the broader SciPy stack.One of Matplotlib’s most important features is its ability to play well with many operating systems and graphics backends. Matplotlib supports dozens of backends and\n",
      "output types, which means you can count on it to work regardless of which operating\n",
      "system you are using or which output format you wish.\n",
      "374\n",
      "Saving Figures to File\n",
      "One nice feature of Matplotlib is the ability to save figures in a wide variety of for‐\n",
      "mats. You can save a figure using the savefig() command. For example, to save the\n",
      "previous figure as a PNG file, you can run this:\n",
      "375\n",
      "\n",
      "Section 14 - Visualization with Plotly\n",
      "376\n",
      "\n",
      "Section 28 - Read data from input files for Plotly Plots\n",
      "377\n",
      "Just as with plt.hist, plt.hist2d has a number of extra options to fine-tune the plot\n",
      "and the binning, which are nicely outlined in the function docstring. Further, just as\n",
      "plt.hist has a counterpart in np.histogram, plt.hist2d has a counterpart in\n",
      "np.histogram2d, which can be used as follows:\n",
      "378\n",
      "\n",
      "Section 12 - Three-Dimensional Plotting in Matplotlib\n",
      "379\n",
      "\n",
      "Section 5 - Visualizing Errors Density and Contour Plots\n",
      "380\n",
      "The file format is inferred from the extension of the given filename.\n",
      "Depending on what backends you have installed, many different file formats are\n",
      "available. You can find the list of supported file types for your system by using the\n",
      "following method of the figure canvas object:\n",
      "381\n",
      "\n",
      "Section 30 - Scatter Charts Plotly Plots\n",
      "382\n",
      "\n",
      "Section 10 - Text & Annotation/Text Position/Arrow Position\n",
      "383\n",
      "\n",
      "Section 36 - Box Plots Plotly Plots\n",
      "384\n",
      "\n",
      "Section 2 - loading from a script\n",
      "385\n",
      "nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sentence_list \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m----> 2\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[43msequence_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(sequence_length) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m6370651\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m, in \u001b[0;36msequence_length\u001b[0;34m(token_list)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token_list[i])\n\u001b[0;32m---> 17\u001b[0m     tmp_text \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m     length_list\u001b[38;5;241m.\u001b[39mappend(tmp_text\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m length_list\n",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m, in \u001b[0;36mtokenizing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenizing\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inputs\n",
      "File \u001b[0;32m~/Desktop/SAMSUNG/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2699\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2689\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2690\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2691\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2692\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2697\u001b[0m )\n\u001b[0;32m-> 2699\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2717\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2718\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/SAMSUNG/venv/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:502\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    481\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    499\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    501\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 502\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/Desktop/SAMSUNG/venv/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:429\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    422\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    423\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    427\u001b[0m )\n\u001b[0;32m--> 429\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    441\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    443\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    453\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
     ]
    }
   ],
   "source": [
    "sentence_list = df.source.to_list()\n",
    "length = sequence_length(sentence_list)\n",
    "print(sum(sequence_length) / 6370651)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86192d54-506e-465a-9a00-d36c439e9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python # For example, here's several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) # Input data files are available in the read-only \"../input/\" directory # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory import os for dirname _ filenames in os walk '/kaggle/input' for filename in filenames print os path join dirname filename # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"  # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
     ]
    }
   ],
   "source": [
    "print(sentence_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5d182-4ecf-4a2e-a107-fd00e4bd7fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
